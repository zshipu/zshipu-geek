<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GBDT on 知识铺的博客</title>
    <link>https://geek.zshipu.com/tags/GBDT/</link>
    <description>Recent content in GBDT on 知识铺的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 15 Mar 2022 10:51:11 +0800</lastBuildDate>
    <atom:link href="https://geek.zshipu.com/tags/GBDT/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>论文笔记结合叶节点嵌入的可解释推荐模型</title>
      <link>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E7%BB%93%E5%90%88%E5%8F%B6%E8%8A%82%E7%82%B9%E5%B5%8C%E5%85%A5%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Tue, 15 Mar 2022 10:51:11 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%E7%BB%93%E5%90%88%E5%8F%B6%E8%8A%82%E7%82%B9%E5%B5%8C%E5%85%A5%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%8E%A8%E8%8D%90%E6%A8%A1%E5%9E%8B/</guid>
      <description>“ 本文主要介绍了发表在 WWW2018 的论文《TEM: Tree-enhanced Embedding Model for Explainable Recommendation》，利用 GBDT 叶子节点进行嵌入表示来获得一个具有解释性的推荐模型” 本文来源：RecLismCat https://zhuanlan.zhihu.com/p/96124874 3 TREE-ENHANCED EMBEDDING METHOD 首先提出 TEM，它结合 MF 用于稀疏数据建模和 GBDTs 用于交叉特征学习的优点。还讨论了可解释性，分析了其复杂性</description>
    </item>
    <item>
      <title>机器学习一文理解的原理</title>
      <link>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%80%E6%96%87%E7%90%86%E8%A7%A3%E7%9A%84%E5%8E%9F%E7%90%86/</link>
      <pubDate>Tue, 15 Mar 2022 10:49:06 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%80%E6%96%87%E7%90%86%E8%A7%A3%E7%9A%84%E5%8E%9F%E7%90%86/</guid>
      <description>https://zhuanlan.zhihu.com/p/29765582 现在网上介绍gbdt算法的文章并不算少，但总体看下来，千篇一律的多，能直达精髓的少，有条理性的就更稀少了。我希望通过此篇文章，能抽丝剥茧般的向初学者介绍清楚这个算法的原理所在。如果仍不清楚可以在文后留言。 1、如何在不改变原有模型的结构上提升模型的拟合能力 假设现在你有样本集 ，然后</description>
    </item>
    <item>
      <title>逻辑回归模型融合原理详解与实战</title>
      <link>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E6%88%98/</link>
      <pubDate>Mon, 14 Mar 2022 16:42:54 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%E4%B8%8E%E5%AE%9E%E6%88%98/</guid>
      <description>来源： Datawhale干货 作者：吴忠强，东北大学，Datawhale成员 一、GBDT+LR简介 协同过滤和矩阵分解存在的劣势就是仅利用了用户与物品相互行为信息进行推荐， 忽视了用户自身特征， 物品自身特征以及上下文信息等，导致生成的结果往往会比较片面。而这次介绍的这个模型是2014年</description>
    </item>
    <item>
      <title>算法解析及实现</title>
      <link>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E7%AE%97%E6%B3%95%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Mon, 14 Mar 2022 16:42:39 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E7%AE%97%E6%B3%95%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%AE%9E%E7%8E%B0/</guid>
      <description>原文地址： https://www.cnblogs.com/wkang/p/9657032.html 1. GBDT + LR 是什么 本质上GBDT+LR是一种具有stacking思想的二分类器模型，所以可以用来解决二分类问题。这个方法出自于Facebook 2014年的论文 Practical Lessons from Predicting Clicks on Ads at Facebook 。 2. GBDT + LR 用在哪 GBDT+LR 使用最广泛的场景是CTR点击率预估，即预测当给用户推送的广告会不会被用户点击。</description>
    </item>
  </channel>
</rss>
