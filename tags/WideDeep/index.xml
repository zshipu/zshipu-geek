<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Wide&amp;Deep on 知识铺的博客</title>
    <link>https://geek.zshipu.com/tags/WideDeep/</link>
    <description>Recent content in Wide&amp;Deep on 知识铺的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 15 Mar 2022 09:07:12 +0800</lastBuildDate>
    <atom:link href="https://geek.zshipu.com/tags/WideDeep/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>算法理论与实践</title>
      <link>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E7%AE%97%E6%B3%95%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Tue, 15 Mar 2022 09:07:12 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E7%AE%97%E6%B3%95%E7%90%86%E8%AE%BA%E4%B8%8E%E5%AE%9E%E8%B7%B5/</guid>
      <description>背景 在CTR预估任务中，线性模型仍占有半壁江山。利用手工构造的交叉组合特征来使线性模型具有“记忆性”，使模型记住共现频率较高的特征组合，往往也能达到一个不错的baseline，且可解释性强。但这种方式有着较为明显的缺点：首先，特征工程需要耗费太多精力。其次，因为模型是强行记住这些</description>
    </item>
    <item>
      <title>技术改进的在文本分类中的应用</title>
      <link>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E6%8A%80%E6%9C%AF%E6%94%B9%E8%BF%9B%E7%9A%84%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</link>
      <pubDate>Tue, 15 Mar 2022 09:05:21 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E6%8A%80%E6%9C%AF%E6%94%B9%E8%BF%9B%E7%9A%84%E5%9C%A8%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8/</guid>
      <description>作者：杨森 01 导读 语音是58同城用户之间的重要沟通媒介，58同城C端用户和B端用户之间可以通过电话（隐私通话）、网络音视频通话（微聊）建立连接，这些场景下产生的语音数据有巨大的挖掘价值。本次议题主要分享语义标签的文本挖掘技术，首先介绍使用主动学习技术解决冷启动时样本少的问题，然后对</description>
    </item>
    <item>
      <title>见微知著你真的搞懂的模型了吗</title>
      <link>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E8%A7%81%E5%BE%AE%E7%9F%A5%E8%91%97%E4%BD%A0%E7%9C%9F%E7%9A%84%E6%90%9E%E6%87%82%E7%9A%84%E6%A8%A1%E5%9E%8B%E4%BA%86%E5%90%97/</link>
      <pubDate>Mon, 14 Mar 2022 16:40:14 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E8%A7%81%E5%BE%AE%E7%9F%A5%E8%91%97%E4%BD%A0%E7%9C%9F%E7%9A%84%E6%90%9E%E6%87%82%E7%9A%84%E6%A8%A1%E5%9E%8B%E4%BA%86%E5%90%97/</guid>
      <description>作者： 王喆 公众号： 王喆的机器学习笔记 为什么在Google的Wide&amp;amp;Deep模型中，要使用带L1正则化项的FTRL作为wide部分的优化方法，而使用AdaGrad作为deep部分的优化方法？ 论文原文的描述是这样的： In the experiments, we used Follow- the-regularized-leader (FTRL) algorithm with L1 regularization as the optimizer for the wide part of the model, and AdaGrad for the deep part. 这</description>
    </item>
  </channel>
</rss>
