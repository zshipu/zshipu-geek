<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>模型压缩 on 知识铺的博客</title>
    <link>https://geek.zshipu.com/tags/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/</link>
    <description>Recent content in 模型压缩 on 知识铺的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 15 Mar 2022 11:30:27 +0800</lastBuildDate>
    <atom:link href="https://geek.zshipu.com/tags/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>推荐广告模型的降本提效压缩策略</title>
      <link>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E6%8E%A8%E8%8D%90%E5%B9%BF%E5%91%8A%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%99%8D%E6%9C%AC%E6%8F%90%E6%95%88%E5%8E%8B%E7%BC%A9%E7%AD%96%E7%95%A5/</link>
      <pubDate>Tue, 15 Mar 2022 11:30:27 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E6%8E%A8%E8%8D%90%E5%B9%BF%E5%91%8A%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%99%8D%E6%9C%AC%E6%8F%90%E6%95%88%E5%8E%8B%E7%BC%A9%E7%AD%96%E7%95%A5/</guid>
      <description>背景 从全局看，深度学习模型规模在过去数年持续的指数膨胀。在模型效果提升的同时，为训练和推理的性能和成本都带来了严峻的挑战。作为应对，出现了大量的模型压缩策略，比如Zero系列的训练时策略。推理时量化、剪枝策略。以及训练推理协同策略，比如蒸馏等等。 广告、推荐的深度学习模型的体积也非</description>
    </item>
  </channel>
</rss>
