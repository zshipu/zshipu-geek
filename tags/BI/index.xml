<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>BI on 知识铺的博客</title>
    <link>https://geek.zshipu.com/tags/BI/</link>
    <description>Recent content in BI on 知识铺的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Sat, 02 Dec 2023 09:42:05 +0800</lastBuildDate>
    <atom:link href="https://geek.zshipu.com/tags/BI/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Flink系列-第42讲：Flink 面试-方案设计篇</title>
      <link>https://geek.zshipu.com/post/bi/flink/2077-%E7%AC%AC42%E8%AE%B2Flink-%E9%9D%A2%E8%AF%95-%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1%E7%AF%87/</link>
      <pubDate>Sat, 02 Dec 2023 09:42:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2077-%E7%AC%AC42%E8%AE%B2Flink-%E9%9D%A2%E8%AF%95-%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1%E7%AF%87/</guid>
      <description>Flink 的方案设计面试题目在面试中，是面试官了解我们项目的最直接的问题，它通常体现在面试者回答自己的项目整体是如何设计的？Flink 在你的项目中起到什么作用？有没有在应用过程中对 Flink 有一些定制开发等。 如何介绍自己的项目，为什么技术选型 Flink 也代表我们对于 Flink 框架的了解程度，我们本课时将介绍 Flink 典</description>
    </item>
    <item>
      <title>Flink系列-第41讲：Flink 面试-源码篇</title>
      <link>https://geek.zshipu.com/post/bi/flink/2076-%E7%AC%AC41%E8%AE%B2Flink-%E9%9D%A2%E8%AF%95-%E6%BA%90%E7%A0%81%E7%AF%87/</link>
      <pubDate>Sat, 02 Dec 2023 09:41:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2076-%E7%AC%AC41%E8%AE%B2Flink-%E9%9D%A2%E8%AF%95-%E6%BA%90%E7%A0%81%E7%AF%87/</guid>
      <description>Flink 的源码篇包含了 Flink 的核心代码实现、Job 提交流程、数据交换、分布式快照机制、Flink SQL 的原理等考察点。你应该记得，我们在前面近 40个课时中几乎每一课时都有一定的篇幅是源码阅读，源码部分的考察是面试时十分重要的一关，如果你对 Flink 的源码有一定的研究而不仅仅停留在使用阶段，那么你的面试</description>
    </item>
    <item>
      <title>Flink系列-第40讲：Flink 面试-进阶篇</title>
      <link>https://geek.zshipu.com/post/bi/flink/2075-%E7%AC%AC40%E8%AE%B2Flink-%E9%9D%A2%E8%AF%95-%E8%BF%9B%E9%98%B6%E7%AF%87/</link>
      <pubDate>Sat, 02 Dec 2023 09:40:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2075-%E7%AC%AC40%E8%AE%B2Flink-%E9%9D%A2%E8%AF%95-%E8%BF%9B%E9%98%B6%E7%AF%87/</guid>
      <description>Flink 面试进阶篇主要包含了 Flink 中的数据传输、容错机制、序列化、数据热点、反压等实际生产环境中遇到的问题等考察点。这一阶段主要考察我们对 Flink 掌握的深度，也是给面试官留下好印象的关键环节。 面试题 1：请谈谈你对 Flink Table &amp;amp; SQL 的了解情况？以及 TableEnvironment 这个类有什么样的作用？ 这道题考察的是对 Flink Table &amp;amp; SQL 的掌握情况，</description>
    </item>
    <item>
      <title>Flink系列-第39讲：Flink 面试-基础篇</title>
      <link>https://geek.zshipu.com/post/bi/flink/2074-%E7%AC%AC39%E8%AE%B2Flink-%E9%9D%A2%E8%AF%95-%E5%9F%BA%E7%A1%80%E7%AF%87/</link>
      <pubDate>Sat, 02 Dec 2023 09:39:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2074-%E7%AC%AC39%E8%AE%B2Flink-%E9%9D%A2%E8%AF%95-%E5%9F%BA%E7%A1%80%E7%AF%87/</guid>
      <description>到目前为止，关于 Flink 的学习我们就告一段落了，接下来我们将进入最后一个面试模块的学习。在当前大背景下，面试这一关是求职者必须要面对的，也能从侧面考察对 Flink 的掌握情况，最后一模块将结合部分实际面试中出现的问题，进行详细分析，帮助大家顺利拿到 Offer。 最后一个面试模块分为了 4 个课时： Flink 面</description>
    </item>
    <item>
      <title>Flink系列- 第38讲：Flink 调用 CEP 实现报警功能</title>
      <link>https://geek.zshipu.com/post/bi/flink/2073-%E7%AC%AC38%E8%AE%B2Flink-%E8%B0%83%E7%94%A8-CEP-%E5%AE%9E%E7%8E%B0%E6%8A%A5%E8%AD%A6%E5%8A%9F%E8%83%BD/</link>
      <pubDate>Sat, 02 Dec 2023 09:38:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2073-%E7%AC%AC38%E8%AE%B2Flink-%E8%B0%83%E7%94%A8-CEP-%E5%AE%9E%E7%8E%B0%E6%8A%A5%E8%AD%A6%E5%8A%9F%E8%83%BD/</guid>
      <description>在上一课时中，我们详细讲解了 Flink CEP 中 Pattern 的分类，需要根据实际生产环境来选择单个模式、组合模式或者模式组。 在前面的课程中我们提到的三种典型场景下，分别根据业务需要实现了 Pattern 的定义，也可以根据自定义的 Pattern 检测到异常事件。那么接下来就需要根据检测到的异常事件发送告警，这一课将从这三种场景入手，</description>
    </item>
    <item>
      <title>Flink系列- 第37讲：自定义 Pattern 和报警规则</title>
      <link>https://geek.zshipu.com/post/bi/flink/2072-%E7%AC%AC37%E8%AE%B2%E8%87%AA%E5%AE%9A%E4%B9%89-Pattern-%E5%92%8C%E6%8A%A5%E8%AD%A6%E8%A7%84%E5%88%99/</link>
      <pubDate>Sat, 02 Dec 2023 09:37:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2072-%E7%AC%AC37%E8%AE%B2%E8%87%AA%E5%AE%9A%E4%B9%89-Pattern-%E5%92%8C%E6%8A%A5%E8%AD%A6%E8%A7%84%E5%88%99/</guid>
      <description>在上一课时提过，PatternStream 是 Flink CEP 对模式匹配后流的抽象和定义，它把 DataStream 和 Pattern 组合到一起，并且基于 PatternStream 提供了一系列的方法，比如 select、process 等。 Flink CEP 的核心在于模式匹配，对于不同模式匹配特性的支持，往往决定相应的 CEP 框架是否能够得到广泛应用。那么 Flink CEP 对模式提供了哪</description>
    </item>
    <item>
      <title>Flink系列-第36讲：自定义消息事件</title>
      <link>https://geek.zshipu.com/post/bi/flink/2071-%E7%AC%AC36%E8%AE%B2%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B6%88%E6%81%AF%E4%BA%8B%E4%BB%B6/</link>
      <pubDate>Sat, 02 Dec 2023 09:36:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2071-%E7%AC%AC36%E8%AE%B2%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B6%88%E6%81%AF%E4%BA%8B%E4%BB%B6/</guid>
      <description>我们在上一课时中讲了 CEP 的基本原理并且用官网的案例介绍了 CEP 的简单应用。在 Flink CEP 中存在多个比较晦涩的概念，如果你对于这些概念理解有困难，我们可以把：创建系列 Pattern，然后利用 NFACompiler 将 Pattern 进行拆分并且创建出 NFA，NFA 包含了 Pattern 中的各个状态和各个状态间转换的表达式。这整个过程我们可以把 Flink</description>
    </item>
    <item>
      <title>Flink系列-第35讲：项目背景和 Flink CEP 简介</title>
      <link>https://geek.zshipu.com/post/bi/flink/2070-%E7%AC%AC35%E8%AE%B2%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E5%92%8C-Flink-CEP-%E7%AE%80%E4%BB%8B/</link>
      <pubDate>Sat, 02 Dec 2023 09:35:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2070-%E7%AC%AC35%E8%AE%B2%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E5%92%8C-Flink-CEP-%E7%AE%80%E4%BB%8B/</guid>
      <description>从这一课时开始我们将进入“Flink CEP 实时预警系统”的学习，本课时先介绍项目的背景、架构设计。 背景 我们在第 11 课时“Flink CEP 复杂事件处理”已经介绍了 Flink CEP 的原理，它是 Flink 提供的复杂事件处理库，也是 Flink 提供的一个非常亮眼的功能，当然更是 Flink 中最难以理解的部分之一。 Complex Event Processing</description>
    </item>
    <item>
      <title>Flink系列-第34讲：Flink 和 Redi 整合以及 Redi Sink 实现</title>
      <link>https://geek.zshipu.com/post/bi/flink/2069-%E7%AC%AC34%E8%AE%B2Flink-%E5%92%8C-Redi-%E6%95%B4%E5%90%88%E4%BB%A5%E5%8F%8A-Redi-Sink-%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Sat, 02 Dec 2023 09:34:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2069-%E7%AC%AC34%E8%AE%B2Flink-%E5%92%8C-Redi-%E6%95%B4%E5%90%88%E4%BB%A5%E5%8F%8A-Redi-Sink-%E5%AE%9E%E7%8E%B0/</guid>
      <description>上一课时我们使用了 3 种方法进行了 PV 和 UV 的计算，分别是全窗口内存统计、使用分组和过期数据剔除、使用 BitMap / 布隆过滤器。到此为止我们已经讲了从数据清洗到水印、窗口设计，PV 和 UV 的计算，接下来需要把结果写入不同的目标库供前端查询使用。 下面我们分别讲解 Flink 和 Redis/MySQL/HBase 是如何整合实现 Flink Sink 的。 Flink Redis Sink 我们在</description>
    </item>
    <item>
      <title>Flink系列-第33讲：Flink 计算 PV、UV 代码实现</title>
      <link>https://geek.zshipu.com/post/bi/flink/2068-%E7%AC%AC33%E8%AE%B2Flink-%E8%AE%A1%E7%AE%97-PVUV-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Sat, 02 Dec 2023 09:33:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2068-%E7%AC%AC33%E8%AE%B2Flink-%E8%AE%A1%E7%AE%97-PVUV-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</guid>
      <description>上一课时我们学习了 Flink 消费 Kafka 数据计算 PV 和 UV 的水印和窗口设计，并且定义了窗口计算的触发器，完成了计算 PV 和 UV 前的所有准备工作。 接下来就需要计算 PV 和 UV 了。在当前业务场景下，根据 userId 进行统计，PV 需要对 userId 进行统计，而 UV 则需要对 userId 进行去重统计。 下面我们使用不同的方法来统计 PV 和 UV。 单窗口内存统</description>
    </item>
    <item>
      <title>Flink系列-第32讲：Flink 和 Kafka 整合时间窗口设计</title>
      <link>https://geek.zshipu.com/post/bi/flink/2067-%E7%AC%AC32%E8%AE%B2Flink-%E5%92%8C-Kafka-%E6%95%B4%E5%90%88%E6%97%B6%E9%97%B4%E7%AA%97%E5%8F%A3%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Sat, 02 Dec 2023 09:32:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2067-%E7%AC%AC32%E8%AE%B2Flink-%E5%92%8C-Kafka-%E6%95%B4%E5%90%88%E6%97%B6%E9%97%B4%E7%AA%97%E5%8F%A3%E8%AE%BE%E8%AE%A1/</guid>
      <description>我们在第 31 课时中讲过，在计算 PV 和 UV 等指标前，用 Flink 将原始数据进行了清洗，清洗完毕的数据被发送到另外的 Kafka Topic 中，接下来我们只需要消费指定 Topic 的数据，然后就可以进行指标计算了。 Flink 消费 Kafka 数据反序列化 上一课时定义了用户的行为信息的 Java 对象，我们现在需要消费新的 Kafka Topic 信息，并且把序列化的消息转化为用</description>
    </item>
    <item>
      <title>Flink系列-第31讲：Kafka 模拟数据生成和发送</title>
      <link>https://geek.zshipu.com/post/bi/flink/2066-%E7%AC%AC31%E8%AE%B2Kafka-%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90%E5%92%8C%E5%8F%91%E9%80%81/</link>
      <pubDate>Sat, 02 Dec 2023 09:31:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2066-%E7%AC%AC31%E8%AE%B2Kafka-%E6%A8%A1%E6%8B%9F%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90%E5%92%8C%E5%8F%91%E9%80%81/</guid>
      <description>第 29 课时讲过，在计算 PV 和 UV 的过程中关键的一个步骤就是进行日志数据的清洗。实际上在其他业务，比如订单数据的统计中，我们也需要过滤掉一些“脏数据”。 所谓“脏数据”是指与我们定义的标准数据结构不一致，或者不需要的数据。因为在数据清洗 ETL 的过程中经常需要进行数据的反序列化解析和 Java 类的映射，</description>
    </item>
    <item>
      <title>Flink系列-第30讲：Flume 和 Kafka 整合和部署</title>
      <link>https://geek.zshipu.com/post/bi/flink/2065-%E7%AC%AC30%E8%AE%B2Flume-%E5%92%8C-Kafka-%E6%95%B4%E5%90%88%E5%92%8C%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Sat, 02 Dec 2023 09:30:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2065-%E7%AC%AC30%E8%AE%B2Flume-%E5%92%8C-Kafka-%E6%95%B4%E5%90%88%E5%92%8C%E9%83%A8%E7%BD%B2/</guid>
      <description>Flume 概述 Flume 是 Hadoop 生态圈子中的一个重要组件，在上一课时中提过，它是一个分布式的、高可靠的、高可用的日志采集工具。 Flume 具有基于流式数据的简单灵活的架构，同时兼具高可靠性、高可用机制和故障转移机制。当我们使用 Flume 收集数据的速度超过下游的写入速度时，Flume 会自动做调整，使得数据的采集和推送能</description>
    </item>
    <item>
      <title>Flink系列-第29讲：项目背景和实时处理系统架构设计</title>
      <link>https://geek.zshipu.com/post/bi/flink/2064-%E7%AC%AC29%E8%AE%B2%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E5%92%8C%E5%AE%9E%E6%97%B6%E5%A4%84%E7%90%86%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Sat, 02 Dec 2023 08:59:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2064-%E7%AC%AC29%E8%AE%B2%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E5%92%8C%E5%AE%9E%E6%97%B6%E5%A4%84%E7%90%86%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/</guid>
      <description>从这一课时开始我们进入“Flink 实时统计 PV、UV”项目的学习。本课时先介绍实时统计项目的背景、架构设计和技术选型。 背景 PV（Page View，网站的浏览量）即页面的浏览次数，一般用来衡量网站用户访问的网页数量。我们可以简单地认为，一个用户每次打开一个页面便会记录一次 PV，也就</description>
    </item>
    <item>
      <title>Flink系列-第28讲：TopN 热门商品功能实现</title>
      <link>https://geek.zshipu.com/post/bi/flink/2063-%E7%AC%AC28%E8%AE%B2TopN-%E7%83%AD%E9%97%A8%E5%95%86%E5%93%81%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Sat, 02 Dec 2023 08:58:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2063-%E7%AC%AC28%E8%AE%B2TopN-%E7%83%AD%E9%97%A8%E5%95%86%E5%93%81%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0/</guid>
      <description>本课时主要讲解 Flink 中的 TopN 功能的设计和实现。 TopN 在我们的业务场景中是十分常见的需求，比如电商场景中求热门商品的销售额、微博每天的热门话题 TopN、贴吧中每天发帖最多的贴吧排名等。TopN 可以进行分组排序，也可以按照需要全局排序，比如若要计算用户下单总金额的 Top 10 时，就需要进行全局排序，然</description>
    </item>
    <item>
      <title>Flink系列-第27讲：Flink Redi Sink 实现</title>
      <link>https://geek.zshipu.com/post/bi/flink/2062-%E7%AC%AC27%E8%AE%B2Flink-Redi-Sink-%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Sat, 02 Dec 2023 08:57:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2062-%E7%AC%AC27%E8%AE%B2Flink-Redi-Sink-%E5%AE%9E%E7%8E%B0/</guid>
      <description>我们在第 12 课时“Flink 常用的 Source 和 Connector”中提过 Flink 提供了比较丰富的用来连接第三方的连接器，可以在官网中找到 Flink 支持的各种各样的连接器。 此外，Flink 还会基于 Apache Bahir 发布一些 Connector，其中就有我们非常熟悉的 Redis。很多人在 Flink 项目中访问 Redis 的方法都是自己进行实现</description>
    </item>
    <item>
      <title>Flink系列-第26讲：Flink 中的聚合函数和累加器的设计和使用</title>
      <link>https://geek.zshipu.com/post/bi/flink/2061-%E7%AC%AC26%E8%AE%B2Flink-%E4%B8%AD%E7%9A%84%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0%E5%92%8C%E7%B4%AF%E5%8A%A0%E5%99%A8%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sat, 02 Dec 2023 08:56:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2061-%E7%AC%AC26%E8%AE%B2Flink-%E4%B8%AD%E7%9A%84%E8%81%9A%E5%90%88%E5%87%BD%E6%95%B0%E5%92%8C%E7%B4%AF%E5%8A%A0%E5%99%A8%E7%9A%84%E8%AE%BE%E8%AE%A1%E5%92%8C%E4%BD%BF%E7%94%A8/</guid>
      <description>我们在第 08 课时中提到了 Flink 所支持的窗口和时间类型，并且在第 25 课时中详细讲解了如何设置时间戳提取器和水印发射器。 实际的业务中，我们在使用窗口的过程中一定是基于窗口进行的聚合计算。例如，计算窗口内的 UV、PV 等，那么 Flink 支持哪些基于窗口的聚合函数？累加器又该如何实现呢？ Flink 支持的窗口函数 我</description>
    </item>
    <item>
      <title>Flink系列-第25讲：Flink 中 watermark 的定义和使用</title>
      <link>https://geek.zshipu.com/post/bi/flink/2060-%E7%AC%AC25%E8%AE%B2Flink-%E4%B8%AD-watermark-%E7%9A%84%E5%AE%9A%E4%B9%89%E5%92%8C%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Sat, 02 Dec 2023 08:45:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2060-%E7%AC%AC25%E8%AE%B2Flink-%E4%B8%AD-watermark-%E7%9A%84%E5%AE%9A%E4%B9%89%E5%92%8C%E4%BD%BF%E7%94%A8/</guid>
      <description>第 08 课时我们提过窗口和时间的概念，Flink 框架支持事件时间、摄入时间和处理时间三种。Watermark（水印）的出现是用于处理数据从 Source 产生，再到转换和输出，在这个过程中由于网络和反压的原因导致了消息乱序问题。 那么在实际的开发过程中，如何正确地使用 Watermark 呢？ 使用 Watermark 必知必会 Watermark 和事件时间</description>
    </item>
    <item>
      <title>Flink系列-第24讲：Flink 消费 Kafka 数据业务开发</title>
      <link>https://geek.zshipu.com/post/bi/flink/2059-%E7%AC%AC24%E8%AE%B2Flink-%E6%B6%88%E8%B4%B9-Kafka-%E6%95%B0%E6%8D%AE%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91/</link>
      <pubDate>Sat, 02 Dec 2023 08:43:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2059-%E7%AC%AC24%E8%AE%B2Flink-%E6%B6%88%E8%B4%B9-Kafka-%E6%95%B0%E6%8D%AE%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91/</guid>
      <description>在上一课时中我们提过在实时计算的场景下，绝大多数的数据源都是消息系统，而 Kafka 从众多的消息中间件中脱颖而出，主要是因为高吞吐、低延迟的特点；同时也讲了 Flink 作为生产者像 Kafka 写入数据的方式和代码实现。这一课时我们将从以下几个方面介绍 Flink 消费 Kafka 中的数据方式和源码实现。 Flink 如何消费 Kafka Flink 在和 Kafka 对接的过</description>
    </item>
    <item>
      <title>Flink系列-第23讲：Mock Kafka 消息并发送</title>
      <link>https://geek.zshipu.com/post/bi/flink/2058-%E7%AC%AC23%E8%AE%B2Mock-Kafka-%E6%B6%88%E6%81%AF%E5%B9%B6%E5%8F%91%E9%80%81/</link>
      <pubDate>Sat, 02 Dec 2023 08:42:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2058-%E7%AC%AC23%E8%AE%B2Mock-Kafka-%E6%B6%88%E6%81%AF%E5%B9%B6%E5%8F%91%E9%80%81/</guid>
      <description>本课时主要讲解 Kafka 的一些核心概念，以及模拟消息并发送。 大数据消息中间件的王者——Kafka 在上一课时中提过在实时计算的场景下，我们绝大多数的数据源都是消息系统。所以，一个强大的消息中间件来支撑高达几十万的 QPS，以及海量数据存储就显得极其重要。 Kafka 从众多的消息中间件中脱颖而出，主要是</description>
    </item>
    <item>
      <title>Flink系列-第22讲：项目背景和整体架构设计</title>
      <link>https://geek.zshipu.com/post/bi/flink/2057-%E7%AC%AC22%E8%AE%B2%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E5%92%8C%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Sat, 02 Dec 2023 08:40:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2057-%E7%AC%AC22%E8%AE%B2%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF%E5%92%8C%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/</guid>
      <description>从这一课时开始我们进入实战课程的学习。本项目是一个模拟实时电商数据大屏，本课时先介绍该项目的背景、架构设计和技术选型。 背景 我们在第 01 课时“Flink 的应用场景和架构模型”中提到过，Flink 应用最广的一个场景便是实时计算大屏。每年的双十一、618 电商大促等，各大公司的实时数据战报</description>
    </item>
    <item>
      <title>Flink系列-第21讲：Flink 在实时计算平台和实时数据仓库中的作用</title>
      <link>https://geek.zshipu.com/post/bi/flink/2056-%E7%AC%AC21%E8%AE%B2Flink-%E5%9C%A8%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%E5%B9%B3%E5%8F%B0%E5%92%8C%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8/</link>
      <pubDate>Sat, 02 Dec 2023 08:39:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2056-%E7%AC%AC21%E8%AE%B2Flink-%E5%9C%A8%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%E5%B9%B3%E5%8F%B0%E5%92%8C%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8/</guid>
      <description>基于 Flink 的实时计算平台 大部分公司随着业务场景的不断丰富，同时在业界经过多年的实践检验，基于 Hadoop 的离线存储体系已经足够成熟。但是离线计算天然时效性不强，一般都是隔天级别的滞后，业务数据随着实践的推移，本身的价值就会逐渐减少。越来越多的场景需要使用实时计算，在这种背景下实时计算平台的需求</description>
    </item>
    <item>
      <title>Flink系列-第20讲：Flink 高级应用之海量数据高效去重</title>
      <link>https://geek.zshipu.com/post/bi/flink/2055-%E7%AC%AC20%E8%AE%B2Flink-%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8%E4%B9%8B%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E9%AB%98%E6%95%88%E5%8E%BB%E9%87%8D/</link>
      <pubDate>Sat, 02 Dec 2023 08:38:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2055-%E7%AC%AC20%E8%AE%B2Flink-%E9%AB%98%E7%BA%A7%E5%BA%94%E7%94%A8%E4%B9%8B%E6%B5%B7%E9%87%8F%E6%95%B0%E6%8D%AE%E9%AB%98%E6%95%88%E5%8E%BB%E9%87%8D/</guid>
      <description>本课时我们主要讲解 Flink 中的海量数据高效去重。 消除重复数据是我们在实际业务中经常遇到的一类问题。在大数据领域，重复数据的删除有助于减少存储所需要的存储容量。而且在一些特定的业务场景中，重复数据是不可接受的，例如，精确统计网站一天的用户数量、在事实表中统计每天发出的快递包裹数量。在传统</description>
    </item>
    <item>
      <title>Flink系列-第19讲：Flink 如何做维表关联</title>
      <link>https://geek.zshipu.com/post/bi/flink/2054-%E7%AC%AC19%E8%AE%B2Flink-%E5%A6%82%E4%BD%95%E5%81%9A%E7%BB%B4%E8%A1%A8%E5%85%B3%E8%81%94/</link>
      <pubDate>Sat, 02 Dec 2023 08:37:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2054-%E7%AC%AC19%E8%AE%B2Flink-%E5%A6%82%E4%BD%95%E5%81%9A%E7%BB%B4%E8%A1%A8%E5%85%B3%E8%81%94/</guid>
      <description>在实际生产中，我们经常会有这样的需求，需要以原始数据流作为基础，然后关联大量的外部表来补充一些属性。例如，我们在订单数据中，希望能得到订单收货人所在省的名称，一般来说订单中会记录一个省的 ID，那么需要根据 ID 去查询外部的维度表补充省名称属性。 在 Flink 流式计算中，我们的一些维度属性一般存</description>
    </item>
    <item>
      <title>Flink系列-第18讲：如何进行生产环境作业监控</title>
      <link>https://geek.zshipu.com/post/bi/flink/2053-%E7%AC%AC18%E8%AE%B2%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%BD%9C%E4%B8%9A%E7%9B%91%E6%8E%A7/</link>
      <pubDate>Sat, 02 Dec 2023 08:36:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2053-%E7%AC%AC18%E8%AE%B2%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%BD%9C%E4%B8%9A%E7%9B%91%E6%8E%A7/</guid>
      <description>本课时主要讲解如何进行生产环境作业监控。 在第 15 课时“如何排查生产环境中的反压问题”中提到过我们应该如何发现任务是否出现反压，Flink 的后台页面是我们发现反压问题的第一选择，其后台页面可以直观、清晰地看到当前作业的运行状态。 在实际生产中，Flink 的后台页面可以方便我们对 Flink Job</description>
    </item>
    <item>
      <title>Flink系列-第17讲：生产环境中的并行度和资源设置</title>
      <link>https://geek.zshipu.com/post/bi/flink/2052-%E7%AC%AC17%E8%AE%B2%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84%E5%B9%B6%E8%A1%8C%E5%BA%A6%E5%92%8C%E8%B5%84%E6%BA%90%E8%AE%BE%E7%BD%AE/</link>
      <pubDate>Sat, 02 Dec 2023 08:35:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2052-%E7%AC%AC17%E8%AE%B2%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84%E5%B9%B6%E8%A1%8C%E5%BA%A6%E5%92%8C%E8%B5%84%E6%BA%90%E8%AE%BE%E7%BD%AE/</guid>
      <description>在使用 Flink 处理生产实际问题时，并行度和资源的配置调优是我们经常要面对的工作之一，如何有效和正确地配置并行度是我们的任务能够高效执行的必要条件。这一课时就来看一下生产环境的并行度和资源配置问题。 Flink 中的计算资源 通常我们说的 Flink 中的计算资源是指具体任务的 Task。首先要理解 Flink 中的计算资源的</description>
    </item>
    <item>
      <title>Flink系列-第16讲：如何处理生产环境中的数据倾斜问题</title>
      <link>https://geek.zshipu.com/post/bi/flink/2051-%E7%AC%AC16%E8%AE%B2%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E9%97%AE%E9%A2%98/</link>
      <pubDate>Sat, 02 Dec 2023 08:33:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2051-%E7%AC%AC16%E8%AE%B2%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E9%97%AE%E9%A2%98/</guid>
      <description>这一课时我们主要讲解如何处理生产环境中的数据倾斜问题。 无论是对于 Flink、Spark 这样的实时计算框架还是 Hive 等离线计算框架，数据量从来都不是问题，真正引起问题导致严重后果的是数据倾斜。所谓数据倾斜，是指在大规模并行处理的数据中，其中某个运行节点处理的数据远远超过其他部分，这会导</description>
    </item>
    <item>
      <title>Flink系列-第15讲：如何排查生产环境中的反压问题</title>
      <link>https://geek.zshipu.com/post/bi/flink/2050-%E7%AC%AC15%E8%AE%B2%E5%A6%82%E4%BD%95%E6%8E%92%E6%9F%A5%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84%E5%8F%8D%E5%8E%8B%E9%97%AE%E9%A2%98/</link>
      <pubDate>Sat, 02 Dec 2023 08:32:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2050-%E7%AC%AC15%E8%AE%B2%E5%A6%82%E4%BD%95%E6%8E%92%E6%9F%A5%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84%E5%8F%8D%E5%8E%8B%E9%97%AE%E9%A2%98/</guid>
      <description>这一课时我们主要讲解生产环境中 Flink 任务经常会遇到的一个问题，即如何处理好反压问题将直接关系到任务的资源使用和稳定运行。 反压问题是流式计算系统中经常碰到的一个问题，如果你的任务出现反压节点，那么就意味着任务数据的消费速度小于数据的生产速度，需要对生产数据的速度进行控制。通常情况下，反</description>
    </item>
    <item>
      <title>Flink系列-第14讲：Flink Exactly-once 实现原理解析</title>
      <link>https://geek.zshipu.com/post/bi/flink/2049-%E7%AC%AC14%E8%AE%B2Flink-Exactly-once-%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/</link>
      <pubDate>Sat, 02 Dec 2023 08:31:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2049-%E7%AC%AC14%E8%AE%B2Flink-Exactly-once-%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E8%A7%A3%E6%9E%90/</guid>
      <description>这一课时我们将讲解 Flink “精确一次”的语义实现原理，同时这也是面试的必考点。 Flink 的“精确一次”处理语义是，Flink 提供了一个强大的语义保证，也就是说在任何情况下都能保证数据对应用产生的效果只有一次，不会多也不会少。 那么 Flink 是如何实现“端到端的精确一次处理”语义的呢？ 背景 通常情况下，流式</description>
    </item>
    <item>
      <title>Flink系列-第13讲：如何实现生产环境中的 Flink 高可用配置</title>
      <link>https://geek.zshipu.com/post/bi/flink/2048-%E7%AC%AC13%E8%AE%B2%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84-Flink-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Sat, 02 Dec 2023 08:30:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2048-%E7%AC%AC13%E8%AE%B2%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%AD%E7%9A%84-Flink-%E9%AB%98%E5%8F%AF%E7%94%A8%E9%85%8D%E7%BD%AE/</guid>
      <description>我们在第 06 课时“Flink 集群安装部署和 HA 配置”中讲解了 Flink 的几种常见部署模式，并且简单地介绍了 HA 配置。 概述 事实上，集群的高可用（High Availablility，以下简称 HA）配置是大数据领域经典的一个问题。 通常 HA 用来描述一个系统经过专门的设计，从而减少停工时间，而保持其服务的</description>
    </item>
    <item>
      <title>Flink系列-第12讲：Flink 常用的 Source 和 Connector</title>
      <link>https://geek.zshipu.com/post/bi/flink/2047-%E7%AC%AC12%E8%AE%B2Flink-%E5%B8%B8%E7%94%A8%E7%9A%84-Source-%E5%92%8C-Connector/</link>
      <pubDate>Sat, 02 Dec 2023 08:29:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2047-%E7%AC%AC12%E8%AE%B2Flink-%E5%B8%B8%E7%94%A8%E7%9A%84-Source-%E5%92%8C-Connector/</guid>
      <description>本课时我们主要介绍 Flink 中支持的 Source 和常用的 Connector。 Flink 作为实时计算领域强大的计算能力，以及与其他系统进行对接的能力都非常强大。Flink 自身实现了多种 Source 和 Connector 方法，并且还提供了多种与第三方系统进行对接的 Connector。 我们可以把这些 Source、Connector 分成以下</description>
    </item>
    <item>
      <title>Flink系列-第10讲：Flink Side OutPut 分流</title>
      <link>https://geek.zshipu.com/post/bi/flink/2045-%E7%AC%AC10%E8%AE%B2Flink-Side-OutPut-%E5%88%86%E6%B5%81/</link>
      <pubDate>Sat, 02 Dec 2023 08:28:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2045-%E7%AC%AC10%E8%AE%B2Flink-Side-OutPut-%E5%88%86%E6%B5%81/</guid>
      <description>这一课时将介绍 Flink 中提供的一个很重要的功能：旁路分流器。 分流场景 我们在生产实践中经常会遇到这样的场景，需把输入源按照需要进行拆分，比如我期望把订单流按照金额大小进行拆分，或者把用户访问日志按照访问者的地理位置进行拆分等。面对这样的需求该如何操作呢？ 分流的方法 通常来说针对不同的场景，</description>
    </item>
    <item>
      <title>Flink系列-第11讲：Flink CEP 复杂事件处理</title>
      <link>https://geek.zshipu.com/post/bi/flink/2046-%E7%AC%AC11%E8%AE%B2Flink-CEP-%E5%A4%8D%E6%9D%82%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86/</link>
      <pubDate>Sat, 02 Dec 2023 08:28:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2046-%E7%AC%AC11%E8%AE%B2Flink-CEP-%E5%A4%8D%E6%9D%82%E4%BA%8B%E4%BB%B6%E5%A4%84%E7%90%86/</guid>
      <description>你好，欢迎来到第 11 课时，这一课时将介绍 Flink 中提供的一个很重要的功能：复杂事件处理 CEP。 背景 Complex Event Processing（CEP）是 Flink 提供的一个非常亮眼的功能，关于 CEP 的解释我们引用维基百科中的一段话： CEP,&amp;nbsp;is&amp;nbsp;event&amp;nbsp;processing&amp;nbsp;that&amp;nbsp;combines&amp;nbsp;data&amp;nbsp;from&amp;nbsp;multiple&amp;nbsp;sources&amp;nbsp;to&amp;nbsp;infer&amp;nbsp;events&amp;nbsp;or&amp;nbsp;patterns&amp;nbsp;that&amp;nbsp;suggest&amp;nbsp;more&amp;nbsp;complicated&amp;nbsp;circumstances.&amp;nbsp;The&amp;nbsp;goal&amp;nbsp;of&amp;nbsp;complex&amp;nbsp;event&amp;nbsp;processing&amp;nbsp;is&amp;nbsp;to&amp;nbsp;identify&amp;nbsp;meaningful&amp;nbsp;events&amp;nbsp;(such&amp;nbsp;as&amp;nbsp;opportunities&amp;nbsp;or&amp;nbsp;threats)&amp;nbsp;and&amp;nbsp;respond&amp;nbsp;to&amp;nbsp;them&amp;nbsp;as&amp;nbsp;quickly&amp;nbsp;as&amp;nbsp;possible. 在我们的实际生产中，随着数据的实时性要求越来越高，实时数据的量也在不断膨胀，在某些业</description>
    </item>
    <item>
      <title>Flink系列-第09讲：Flink 状态与容错</title>
      <link>https://geek.zshipu.com/post/bi/flink/2044-%E7%AC%AC09%E8%AE%B2Flink-%E7%8A%B6%E6%80%81%E4%B8%8E%E5%AE%B9%E9%94%99/</link>
      <pubDate>Sat, 02 Dec 2023 08:27:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2044-%E7%AC%AC09%E8%AE%B2Flink-%E7%8A%B6%E6%80%81%E4%B8%8E%E5%AE%B9%E9%94%99/</guid>
      <description>这一课时我们主要讲解 Flink 的状态和容错。 在 Flink 的框架中，进行有状态的计算是 Flink 最重要的特性之一。所谓的状态，其实指的是 Flink 程序的中间计算结果。Flink 支持了不同类型的状态，并且针对状态的持久化还提供了专门的机制和状态管理器。 状态 我们在 Flink 的官方博客中找到这样一段话，可以认为这是对状态的定义</description>
    </item>
    <item>
      <title>Flink系列-第08讲：Flink 窗口、时间和水印</title>
      <link>https://geek.zshipu.com/post/bi/flink/2043-%E7%AC%AC08%E8%AE%B2Flink-%E7%AA%97%E5%8F%A3%E6%97%B6%E9%97%B4%E5%92%8C%E6%B0%B4%E5%8D%B0/</link>
      <pubDate>Sat, 02 Dec 2023 08:26:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2043-%E7%AC%AC08%E8%AE%B2Flink-%E7%AA%97%E5%8F%A3%E6%97%B6%E9%97%B4%E5%92%8C%E6%B0%B4%E5%8D%B0/</guid>
      <description>本课时主要介绍 Flink 中的时间和水印。 我们在之前的课时中反复提到过窗口和时间的概念，Flink 框架中支持事件时间、摄入时间和处理时间三种。而当我们在流式计算环境中数据从 Source 产生，再到转换和输出，这个过程由于网络和反压的原因会导致消息乱序。因此，需要有一个机制来解决这个问题，这个特别的机制</description>
    </item>
    <item>
      <title>Flink系列-第07讲：Flink 常见核心概念分析</title>
      <link>https://geek.zshipu.com/post/bi/flink/2042-%E7%AC%AC07%E8%AE%B2Flink-%E5%B8%B8%E8%A7%81%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E5%88%86%E6%9E%90/</link>
      <pubDate>Sat, 02 Dec 2023 08:25:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2042-%E7%AC%AC07%E8%AE%B2Flink-%E5%B8%B8%E8%A7%81%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E5%88%86%E6%9E%90/</guid>
      <description>在 Flink 这个框架中，有很多独有的概念，比如分布式缓存、重启策略、并行度等，这些概念是我们在进行任务开发和调优时必须了解的，这一课时我将会从原理和应用场景分别介绍这些概念。 分布式缓存 熟悉 Hadoop 的你应该知道，分布式缓存最初的思想诞生于 Hadoop 框架，Hadoop 会将一些数据或者文件缓存在 HDFS 上，在分布</description>
    </item>
    <item>
      <title>Flink系列-第06讲：Flink 集群安装部署和 HA 配置</title>
      <link>https://geek.zshipu.com/post/bi/flink/2041-%E7%AC%AC06%E8%AE%B2Flink-%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E5%92%8C-HA-%E9%85%8D%E7%BD%AE/</link>
      <pubDate>Sat, 02 Dec 2023 08:24:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2041-%E7%AC%AC06%E8%AE%B2Flink-%E9%9B%86%E7%BE%A4%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E5%92%8C-HA-%E9%85%8D%E7%BD%AE/</guid>
      <description>我们在这一课时将讲解 Flink 常见的部署模式：本地模式、Standalone 模式和 Flink On Yarn 模式，然后分别讲解三种模式的使用场景和部署中常见的问题，最后将讲解在生产环境中 Flink 集群的高可用配置。 Flink 常见的部署模式 环境准备 在绝大多数情况下，我们的 Flink 都是运行在 Unix 环境中的，推荐在 Mac OS 或者 Linux 环境下运行 Fl</description>
    </item>
    <item>
      <title>Flink系列-第05讲：Flink SQL &amp; Table 编程和案例.md</title>
      <link>https://geek.zshipu.com/post/bi/flink/2040-%E7%AC%AC05%E8%AE%B2Flink-SQL-Table-%E7%BC%96%E7%A8%8B%E5%92%8C%E6%A1%88%E4%BE%8B/</link>
      <pubDate>Sat, 02 Dec 2023 08:23:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2040-%E7%AC%AC05%E8%AE%B2Flink-SQL-Table-%E7%BC%96%E7%A8%8B%E5%92%8C%E6%A1%88%E4%BE%8B/</guid>
      <description>我们在第 02 课时中使用 Flink Table &amp;amp; SQL 的 API 实现了最简单的 WordCount 程序。在这一课时中，将分别从 Flink Table &amp;amp; SQL 的背景和编程模型、常见的 API、算子和内置函数等对 Flink Table &amp;amp; SQL 做一个详细的讲解和概括，最后模拟了一个实际业务场景使用 Flink Table &amp;amp; SQL 开发。 Flink Table &amp;amp; SQL 概述 背景 我们在前面的课时中讲过 Flink 的分层模型，Flink 自身提供</description>
    </item>
    <item>
      <title>Flink系列-第04讲：Flink 常用的 DataSet 和 DataStream API</title>
      <link>https://geek.zshipu.com/post/bi/flink/2039-%E7%AC%AC04%E8%AE%B2Flink-%E5%B8%B8%E7%94%A8%E7%9A%84-DataSet-%E5%92%8C-DataStream-API/</link>
      <pubDate>Sat, 02 Dec 2023 08:22:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2039-%E7%AC%AC04%E8%AE%B2Flink-%E5%B8%B8%E7%94%A8%E7%9A%84-DataSet-%E5%92%8C-DataStream-API/</guid>
      <description>本课时我们主要介绍 Flink 的 DataSet 和 DataStream 的 API，并模拟了实时计算的场景，详细讲解了 DataStream 常用的 API 的使用。 说好的流批一体呢 现状 在前面的课程中，曾经提到过，Flink 很重要的一个特点是“流批一体”，然而事实上 Flink 并没有完全做到所谓的“流批一体”，即编写一套代码，可以同时支持流式计算场景和批量计算的场</description>
    </item>
    <item>
      <title>Flink系列-第03讲：Flink 的编程模型与其他框架比较</title>
      <link>https://geek.zshipu.com/post/bi/flink/2038-%E7%AC%AC03%E8%AE%B2Flink-%E7%9A%84%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%85%B6%E4%BB%96%E6%A1%86%E6%9E%B6%E6%AF%94%E8%BE%83/</link>
      <pubDate>Sat, 02 Dec 2023 08:21:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2038-%E7%AC%AC03%E8%AE%B2Flink-%E7%9A%84%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%85%B6%E4%BB%96%E6%A1%86%E6%9E%B6%E6%AF%94%E8%BE%83/</guid>
      <description>本课时我们主要介绍 Flink 的编程模型与其他框架比较。 本课时的内容主要介绍基于 Flink 的编程模型，包括 Flink 程序的基础处理语义和基本构成模块，并且和 Spark、Storm 进行比较，Flink 作为最新的分布式大数据处理引擎具有哪些独特的优势呢？ Flink 的核心语义和架构模型 我们在讲解 Flink 程序的编程模型之前，先</description>
    </item>
    <item>
      <title>Flink系列-第02讲：Flink 入门程序 WordCount 和 SQL 实现</title>
      <link>https://geek.zshipu.com/post/bi/flink/2037-%E7%AC%AC02%E8%AE%B2Flink-%E5%85%A5%E9%97%A8%E7%A8%8B%E5%BA%8F-WordCount-%E5%92%8C-SQL-%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Sat, 02 Dec 2023 08:20:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2037-%E7%AC%AC02%E8%AE%B2Flink-%E5%85%A5%E9%97%A8%E7%A8%8B%E5%BA%8F-WordCount-%E5%92%8C-SQL-%E5%AE%9E%E7%8E%B0/</guid>
      <description>本课时我们主要介绍 Flink 的入门程序以及 SQL 形式的实现。 上一课时已经讲解了 Flink 的常用应用场景和架构模型设计，这一课时我们将会从一个最简单的 WordCount 案例作为切入点，并且同时使用 SQL 方式进行实现，为后面的实战课程打好基础。 我们首先会从环境搭建入手，介绍如何搭建本地调试环境的脚手架；然后分别从DataS</description>
    </item>
    <item>
      <title>Flink系列-第01讲：Flink 的应用场景和架构模型</title>
      <link>https://geek.zshipu.com/post/bi/flink/2036-%E7%AC%AC01%E8%AE%B2Flink-%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E5%92%8C%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Sat, 02 Dec 2023 08:19:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2036-%E7%AC%AC01%E8%AE%B2Flink-%E7%9A%84%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%E5%92%8C%E6%9E%B6%E6%9E%84%E6%A8%A1%E5%9E%8B/</guid>
      <description>你好，欢迎来到第 01 课时，本课时我们主要介绍 Flink 的应用场景和架构模型。 实时计算最好的时代 在过去的十年里，面向数据时代的实时计算技术接踵而至。从我们最初认识的 Storm，再到 Spark 的异军突起，迅速占领了整个实时计算领域。直到 2019 年 1 月底，阿里巴巴内部版本 Flink 正式开源！一石激起千层浪，Flink</description>
    </item>
    <item>
      <title>Flink系列-开篇词：实时计算领域最锋利的武器 Flink</title>
      <link>https://geek.zshipu.com/post/bi/flink/2035-%E5%BC%80%E7%AF%87%E8%AF%8D%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%E9%A2%86%E5%9F%9F%E6%9C%80%E9%94%8B%E5%88%A9%E7%9A%84%E6%AD%A6%E5%99%A8-Flink/</link>
      <pubDate>Sat, 02 Dec 2023 08:18:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/2035-%E5%BC%80%E7%AF%87%E8%AF%8D%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97%E9%A2%86%E5%9F%9F%E6%9C%80%E9%94%8B%E5%88%A9%E7%9A%84%E6%AD%A6%E5%99%A8-Flink/</guid>
      <description>你好，欢迎来到 Flink 专栏，我是王知无，目前在某一线互联网公司从事数据平台架构和研发工作多年，算是整个大数据开发领域的老兵了。 我最早从 Release 版本开始关注 Flink，可以说是国内第一批钻研 Flink 的开发者，后来基于 Flink 开发过实时计算业务应用、实时数据仓库以及监控报警系统，在这个过程中积累了大量宝贵的</description>
    </item>
    <item>
      <title>基于Flink-CDC数据同步⽅案</title>
      <link>https://geek.zshipu.com/post/bi/flink/%E5%9F%BA%E4%BA%8EFlink-CDC%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%A1%88/</link>
      <pubDate>Sat, 03 Sep 2022 09:18:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/%E5%9F%BA%E4%BA%8EFlink-CDC%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%A1%88/</guid>
      <description>前言 在业务数据处理过程中，我们时常会遇到不同业务模块 / 存储系统间实时数据同步需求。比如， 报表模块依赖订单模块数据进行增量更新，检索引擎依赖业务数据进行实时同步等。针对这类场景，我们目前采用了Flink-CDC的技术方案用于数据同步。 Flink-CDC（CDC，全称是 Change Data Captu</description>
    </item>
    <item>
      <title>Doris核心功能介绍——数据模型和物化视图</title>
      <link>https://geek.zshipu.com/post/bi/doris/Doris%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD%E4%BB%8B%E7%BB%8D%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE/</link>
      <pubDate>Sat, 03 Sep 2022 09:09:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/doris/Doris%E6%A0%B8%E5%BF%83%E5%8A%9F%E8%83%BD%E4%BB%8B%E7%BB%8D%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E5%92%8C%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE/</guid>
      <description>Doris是什么 首先 Doris 是一个有着MPP架构的分析型数据库产品。对于PB数量级、结构化数据可以做到亚秒级查询响应。使用上兼容MySQL协议，语法是标准的SQL。Doris本身不依赖任何其他系统，相比Hadoop生态产品更易于运维。 应用场景包括：固定历史报表分析、实时数据分析、交互式</description>
    </item>
    <item>
      <title>Flink规则引擎实践</title>
      <link>https://geek.zshipu.com/post/bi/flink/Flink%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Fri, 02 Sep 2022 09:18:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/Flink%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E%E5%AE%9E%E8%B7%B5/</guid>
      <description>一、实时规则引擎架构 业务系统产生的行为日志数据被日志采集服务器收集，通过Flume将数据存入Kafka指定topic，由Flink消费Kafka对应的topic来进行用户行为事件分析【通过FlinkKafkaComsumer传入参数(1)topic名称(2)反序列化模式Deser</description>
    </item>
    <item>
      <title>大数据之初识Doris（一）</title>
      <link>https://geek.zshipu.com/post/bi/doris/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E5%88%9D%E8%AF%86Doris%E4%B8%80/</link>
      <pubDate>Fri, 02 Sep 2022 09:09:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/doris/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%E5%88%9D%E8%AF%86Doris%E4%B8%80/</guid>
      <description>一、Doris简介 Apache Doris是一个现代化的基于MPP（大规模并行处理）技术的分析型数据库产品，MPP技术即将同一个任务并行的分散到多个服务器和节点上，每个节点计算完成后，在将各自的结果汇总在一起得到最终的结果，与Hadoop相似，效率很高，亚秒级内即可查询出结果。 二、核心特性 基</description>
    </item>
    <item>
      <title>002 Flink 实战案例开发（一）：数据清洗</title>
      <link>https://geek.zshipu.com/post/bi/flink/002-Flink-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E5%BC%80%E5%8F%91%E4%B8%80%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/</link>
      <pubDate>Thu, 01 Sep 2022 11:18:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/002-Flink-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E5%BC%80%E5%8F%91%E4%B8%80%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/</guid>
      <description>1、应用场景分析 参考徐崴老师Flink项目 数据清洗【实时ETL】 数据报表 1.1、数据清洗【实时ETL】 1.1.1、需求分析 针对算法产生的日志数据进行清洗拆分 算法产生的日志数据是嵌套大JSON格式（json嵌套json），需要拆分打平 针对算法中的国家字段进行大区转换 最后把不同类型的</description>
    </item>
    <item>
      <title>003 Flink 实战案例开发（二）：数据报表</title>
      <link>https://geek.zshipu.com/post/bi/flink/003-Flink-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E5%BC%80%E5%8F%91%E4%BA%8C%E6%95%B0%E6%8D%AE%E6%8A%A5%E8%A1%A8/</link>
      <pubDate>Thu, 01 Sep 2022 11:18:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/003-Flink-%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B%E5%BC%80%E5%8F%91%E4%BA%8C%E6%95%B0%E6%8D%AE%E6%8A%A5%E8%A1%A8/</guid>
      <description>1、应用场景分析 数据清洗【实时ETL】 数据报表 1.1、数据报表 1.1.1、架构图 1.1.2、需求分析 主要针对直播/短视频平台审核指标的统计 统计不同大区每1 min内过审(上架)的数据量 统计不同大区每1 min内未过审(下架)的数据量 统计不同大区每1 min内加黑名单的数据量 2、Data</description>
    </item>
    <item>
      <title>001 Flink_CDC搭建及简单使用</title>
      <link>https://geek.zshipu.com/post/bi/flink/001-Flink_CDC%E6%90%AD%E5%BB%BA%E5%8F%8A%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/</link>
      <pubDate>Thu, 01 Sep 2022 10:18:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/001-Flink_CDC%E6%90%AD%E5%BB%BA%E5%8F%8A%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/</guid>
      <description>Flink_CDC搭建及简单使用 1.CDC简介： CDC （Change Data Capture） ，在广义的概念上，只要能捕获数据变更的技术，都可以称为 CDC 。但通常我们说的CDC 技术主要面向数据库（包括常见的mysql,Oracle, MongoDB等）的变更，是一种用于捕获数据库中数据变更的技术。</description>
    </item>
    <item>
      <title>000 Flink 第一次接触</title>
      <link>https://geek.zshipu.com/post/bi/flink/000-Flink-%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%BF%9E%E6%8E%A5/</link>
      <pubDate>Thu, 01 Sep 2022 09:18:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/flink/000-Flink-%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%BF%9E%E6%8E%A5/</guid>
      <description>Flink 操作场景 # Apache Flink 可以以多种方式在不同的环境中部署，抛开这种多样性而言，Flink 集群的基本构建方式和操作原则仍然是相同的。 在这篇文章里，你将会学习如何管理和运行 Flink 任务，了解如何部署和监控应用程序、Flink 如何从失败作业中进行恢复，同时你还会学习如何执行一些日常操作任务，如升级和</description>
    </item>
    <item>
      <title>004 Apache Doris 数据模型</title>
      <link>https://geek.zshipu.com/post/bi/doris/004-Apache-Doris-%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</link>
      <pubDate>Thu, 01 Sep 2022 09:16:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/doris/004-Apache-Doris-%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/</guid>
      <description>数据模型 本文档主要从逻辑层面，描述 Doris 的数据模型，以帮助用户更好的使用 Doris 应对不同的业务场景。 基本概念 在 Doris 中，数据以表（Table）的形式进行逻辑上的描述。 一张表包括行（Row）和列（Column）。Row 即用户的一行数据。Column 用于描述一行数据中不同的字段。 Column 可以分为两大类：</description>
    </item>
    <item>
      <title>003 Apache Doris 创建表</title>
      <link>https://geek.zshipu.com/post/bi/doris/003-Apache-Doris-%E5%88%9B%E5%BB%BA%E8%A1%A8/</link>
      <pubDate>Thu, 01 Sep 2022 09:14:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/doris/003-Apache-Doris-%E5%88%9B%E5%BB%BA%E8%A1%A8/</guid>
      <description>2.3 建表 使用 CREATE TABLE 命令建立一个表(Table)。更多详细参数可以查看: HELP CREATE TABLE; 首先切换数据库: USE example_db; Doris支持支持单分区和复合分区两种建表方式。 2.3.1 单分区 建立一个名字为 table1 的逻辑表。分桶列为 siteid，桶数为 10。 这个表的 schema 如下： siteid：类型是INT（4字节）, 默认值为10 cit</description>
    </item>
    <item>
      <title>002 Apache Doris 创建数据库</title>
      <link>https://geek.zshipu.com/post/bi/doris/002-Apache-Doris-%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
      <pubDate>Thu, 01 Sep 2022 09:12:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/doris/002-Apache-Doris-%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%BA%93/</guid>
      <description>2.1 创建数据库 初始可以通过 root 或 admin 用户创建数据库： CREATE DATABASE example_db; 所有命令都可以使用 ‘HELP command;’ 查看到详细的语法帮助。如：HELP CREATE DATABASE; 如果不清楚命令的全名，可以使用 “help 命令某一字段” 进行模糊查询。如键入 ‘HELP CREATE’，可以匹配到 CREATE DATABASE, CREATE TABLE, CREATE USER 等命令。 数据库创建完成</description>
    </item>
    <item>
      <title>001 Apache Doris 安装</title>
      <link>https://geek.zshipu.com/post/bi/doris/001-Apache-Doris-%E5%AE%89%E8%A3%85/</link>
      <pubDate>Thu, 01 Sep 2022 09:10:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/doris/001-Apache-Doris-%E5%AE%89%E8%A3%85/</guid>
      <description>一.编译前准备 1.1 环境准备 主机配置: IP 主机名 部署 192.168.9.119 hw5 FE FS_Broker 192.168.9.120 hw6 BE FS_Broker 192.168.9.121 hw7 BE FS_Broker,FE Observer 192.168.9.122 hw8 BE FS_Broker 硬件配置： 每台主机：CPU4核、内存8G、硬盘150G 软件版本： 名称 版本 操作系统 CentOS release 7.8 (Final) 64位 JDK 1.11 yum install -y java-11-openjdk-devel.x86_64 ln -s /usr/lib/jvm/java-11-openjdk-11.0.13.0.8-1.el7_9.x86_64 /usr/lib/jvm/java11 vi /etc/profile JAVA_HOME=/usr/lib/jvm/java11 PATH=$JAVA_HOME/bin:$PATH CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export JAVA_HOME export PATH export CLASSPATH source /etc/profile 1.2 安装Docker 1.2.1 卸载旧版本 yum remove docker docker-common docker-selinux docker-engine 1.2.2 安装需要的软件包</description>
    </item>
    <item>
      <title>000 Apache Doris 简介</title>
      <link>https://geek.zshipu.com/post/bi/doris/000-Apache-Doris-%E7%AE%80%E4%BB%8B/</link>
      <pubDate>Thu, 01 Sep 2022 09:09:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/doris/000-Apache-Doris-%E7%AE%80%E4%BB%8B/</guid>
      <description>一. Doris简介 Apache Doris是一个现代化的MPP分析型数据库产品。仅需亚秒级响应时间即可获得查询结果，有效地支持实时数据分析。Apache Doris的分布式架构非常简洁，易于运维，并且可以支持10PB以上的超大数据集。 Apache Doris可以满足多种数据分析需求，例如固定历史报表，实时</description>
    </item>
    <item>
      <title>BI-数据仓-数据体系的要义：贴源、规范、建模、标签、设计、建设</title>
      <link>https://geek.zshipu.com/post/bi/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB%E7%9A%84%E8%A6%81%E4%B9%89%E8%B4%B4%E6%BA%90%E8%A7%84%E8%8C%83%E5%BB%BA%E6%A8%A1%E6%A0%87%E7%AD%BE%E8%AE%BE%E8%AE%A1%E5%BB%BA%E8%AE%BE/</link>
      <pubDate>Mon, 29 Aug 2022 19:30:00 +0000</pubDate>
      <guid>https://geek.zshipu.com/post/bi/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E4%BD%93%E7%B3%BB%E7%9A%84%E8%A6%81%E4%B9%89%E8%B4%B4%E6%BA%90%E8%A7%84%E8%8C%83%E5%BB%BA%E6%A8%A1%E6%A0%87%E7%AD%BE%E8%AE%BE%E8%AE%A1%E5%BB%BA%E8%AE%BE/</guid>
      <description>.</description>
    </item>
    <item>
      <title>Apache Doris 是一个基于 MPP 架构的高性能、实时的分析型数据库</title>
      <link>https://geek.zshipu.com/post/bi/doris/Apache-Doris-%E6%98%AF%E4%B8%80%E4%B8%AA%E5%9F%BA%E4%BA%8E-MPP-%E6%9E%B6%E6%9E%84%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BD%E5%AE%9E%E6%97%B6%E7%9A%84%E5%88%86%E6%9E%90%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/</link>
      <pubDate>Wed, 17 Aug 2022 09:14:05 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/bi/doris/Apache-Doris-%E6%98%AF%E4%B8%80%E4%B8%AA%E5%9F%BA%E4%BA%8E-MPP-%E6%9E%B6%E6%9E%84%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BD%E5%AE%9E%E6%97%B6%E7%9A%84%E5%88%86%E6%9E%90%E5%9E%8B%E6%95%B0%E6%8D%AE%E5%BA%93/</guid>
      <description>版本：1.1 快速开始 Apache Doris 是一个基于 MPP 架构的高性能、实时的分析型数据库，以极速易用的特点被人们所熟知，仅需亚秒级响应时间即可返回海量数据下的查询结果，不仅可以支持高并发的点查询场景，也能支持高吞吐的复杂分析场景，这个简短的指南将告诉你如何下载 Doris 最新稳定版本，在单节点上安装并运行它，</description>
    </item>
    <item>
      <title>Metabase教程系列-各种可视化元素基本运用</title>
      <link>https://geek.zshipu.com/post/bi/%E5%8F%AF%E8%A7%86%E5%8C%96/Metabase%E6%95%99%E7%A8%8B%E7%B3%BB%E5%88%97-%E5%90%84%E7%A7%8D%E5%8F%AF%E8%A7%86%E5%8C%96%E5%85%83%E7%B4%A0%E5%9F%BA%E6%9C%AC%E8%BF%90%E7%94%A8/</link>
      <pubDate>Tue, 26 Oct 2021 10:12:00 +0000</pubDate>
      <guid>https://geek.zshipu.com/post/bi/%E5%8F%AF%E8%A7%86%E5%8C%96/Metabase%E6%95%99%E7%A8%8B%E7%B3%BB%E5%88%97-%E5%90%84%E7%A7%8D%E5%8F%AF%E8%A7%86%E5%8C%96%E5%85%83%E7%B4%A0%E5%9F%BA%E6%9C%AC%E8%BF%90%E7%94%A8/</guid>
      <description>数字 数字选项用于显示单个数字，漂亮又大。数字选项包括： 添加字符前缀或后缀（因此您可以做一些事情，如把一个货币符号在前面或一个百分比在年底），） **设置要包含的十进制位置数，**以及 将结果乘以数字（如要将十进制乘以 100，使其看起来像百分比）。如果你想除以一个数字，那么只需乘以小数</description>
    </item>
    <item>
      <title>Metabase教程系列-Metabase基本认识和初级分析</title>
      <link>https://geek.zshipu.com/post/bi/%E5%8F%AF%E8%A7%86%E5%8C%96/Metabase%E6%95%99%E7%A8%8B%E7%B3%BB%E5%88%97-Metabase%E5%9F%BA%E6%9C%AC%E8%AE%A4%E8%AF%86%E5%92%8C%E5%88%9D%E7%BA%A7%E5%88%86%E6%9E%90/</link>
      <pubDate>Mon, 25 Oct 2021 10:12:00 +0000</pubDate>
      <guid>https://geek.zshipu.com/post/bi/%E5%8F%AF%E8%A7%86%E5%8C%96/Metabase%E6%95%99%E7%A8%8B%E7%B3%BB%E5%88%97-Metabase%E5%9F%BA%E6%9C%AC%E8%AE%A4%E8%AF%86%E5%92%8C%E5%88%9D%E7%BA%A7%E5%88%86%E6%9E%90/</guid>
      <description>Metabase介绍及基础使用 Metabase概述 Metabase是基于一个java语言开发的一款开源的数据分析工具，主要通过给公司人员提问题的方式（ps:相对于Metabase中的Question）对数据进行根据自己的需求进行提炼。帮助你把数据库中的数据更好的,多样化的呈现给更</description>
    </item>
    <item>
      <title>BI-可视化-Metabase与CBoard差异化分析说明</title>
      <link>https://geek.zshipu.com/post/bi/%E5%8F%AF%E8%A7%86%E5%8C%96/BI-%E5%8F%AF%E8%A7%86%E5%8C%96-Metabase%E4%B8%8ECBoard%E5%B7%AE%E5%BC%82%E5%8C%96%E5%88%86%E6%9E%90%E8%AF%B4%E6%98%8E/</link>
      <pubDate>Mon, 25 Oct 2021 10:11:00 +0000</pubDate>
      <guid>https://geek.zshipu.com/post/bi/%E5%8F%AF%E8%A7%86%E5%8C%96/BI-%E5%8F%AF%E8%A7%86%E5%8C%96-Metabase%E4%B8%8ECBoard%E5%B7%AE%E5%BC%82%E5%8C%96%E5%88%86%E6%9E%90%E8%AF%B4%E6%98%8E/</guid>
      <description>这里的CBoard是在原生态CBoard基础上进行二次开发之后的BI工具，以下内容将其称为Mydata。 相似点 1.可以下载查询出的数据。 2.底层均采用java开发。 3.可视化拖拉拽查询方式。 4.均支持二次开发。 5.支持在图表上方进行数值筛选。 6.均支持自定义表达式，Metabas</description>
    </item>
    <item>
      <title>BI-可视化-superset、metabase、redash三个开源BI工具的个人使用心得及分析</title>
      <link>https://geek.zshipu.com/post/bi/%E5%8F%AF%E8%A7%86%E5%8C%96/BI-%E5%8F%AF%E8%A7%86%E5%8C%96-supersetmetabaseredash%E4%B8%89%E4%B8%AA%E5%BC%80%E6%BA%90BI%E5%B7%A5%E5%85%B7%E7%9A%84%E4%B8%AA%E4%BA%BA%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97%E5%8F%8A%E5%88%86%E6%9E%90/</link>
      <pubDate>Mon, 25 Oct 2021 10:10:00 +0000</pubDate>
      <guid>https://geek.zshipu.com/post/bi/%E5%8F%AF%E8%A7%86%E5%8C%96/BI-%E5%8F%AF%E8%A7%86%E5%8C%96-supersetmetabaseredash%E4%B8%89%E4%B8%AA%E5%BC%80%E6%BA%90BI%E5%B7%A5%E5%85%B7%E7%9A%84%E4%B8%AA%E4%BA%BA%E4%BD%BF%E7%94%A8%E5%BF%83%E5%BE%97%E5%8F%8A%E5%88%86%E6%9E%90/</guid>
      <description>数据可视化也是大数据领域里极为关键的一环，通过计算引擎算出来的数据往往需要以合适又美观的图表形式展示给产品经理和决策者，一开始笔者的部门用的是SpringBoot+ECharts的经典组合来做可视化的，确实功能很强也很灵活，但后来随着统计需求越来越多，每来一个新需求都要写大量的重</description>
    </item>
    <item>
      <title>BI-ETL-在10分钟内掌握Apache Airflow</title>
      <link>https://geek.zshipu.com/post/bi/%E5%A4%A7%E6%95%B0%E6%8D%AE/BI-ETL-%E5%9C%A810%E5%88%86%E9%92%9F%E5%86%85%E6%8E%8C%E6%8F%A1Apache-Airflow/</link>
      <pubDate>Sun, 24 Oct 2021 19:44:00 +0000</pubDate>
      <guid>https://geek.zshipu.com/post/bi/%E5%A4%A7%E6%95%B0%E6%8D%AE/BI-ETL-%E5%9C%A810%E5%88%86%E9%92%9F%E5%86%85%E6%8E%8C%E6%8F%A1Apache-Airflow/</guid>
      <description>介绍 一个pache 气流是用于协调复杂工作流和数据处理管道的开源工具。它是一个平台，以编程方式安排和监控预定工作的工作流程。 Apache 气流使您的工作流程简单、井然有序、系统化，因此可以根据要求轻松编写和安排时间。 让我们从基础知识开始。 **我们所说的工作流程是什么意思？ 工作流程可以是您的简单</description>
    </item>
    <item>
      <title>BI-ETL-开始使用Apache Airflow</title>
      <link>https://geek.zshipu.com/post/bi/%E5%A4%A7%E6%95%B0%E6%8D%AE/BI-ETL-%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B-101-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8Apache-Airflow/</link>
      <pubDate>Sun, 24 Oct 2021 19:41:00 +0000</pubDate>
      <guid>https://geek.zshipu.com/post/bi/%E5%A4%A7%E6%95%B0%E6%8D%AE/BI-ETL-%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B-101-%E5%BC%80%E5%A7%8B%E4%BD%BF%E7%94%A8Apache-Airflow/</guid>
      <description>概述 了解Apache Airflow及其部件的需求 我们将创建我们的第一个 DAG 获得现场板球得分使用Apache Airflow 介绍 工作自动化在任何行业都发挥着关键作用，是实现功能效率的最快方法之一。但是，我们中的许多人不知道如何自动化一些任务，并结束在手动做同样的事情一次又一次的循环。 我们大多数人必</description>
    </item>
    <item>
      <title>BI-ETL-Apache Airflow简介：5分钟内开始</title>
      <link>https://geek.zshipu.com/post/bi/%E5%A4%A7%E6%95%B0%E6%8D%AE/BI-ETL-Apache-Airflow%E7%AE%80%E4%BB%8B5%E5%88%86%E9%92%9F%E5%86%85%E5%BC%80%E5%A7%8B/</link>
      <pubDate>Sun, 24 Oct 2021 19:40:00 +0000</pubDate>
      <guid>https://geek.zshipu.com/post/bi/%E5%A4%A7%E6%95%B0%E6%8D%AE/BI-ETL-Apache-Airflow%E7%AE%80%E4%BB%8B5%E5%88%86%E9%92%9F%E5%86%85%E5%BC%80%E5%A7%8B/</guid>
      <description>如果你在大数据工作，你很可能听说过Apache Airflow。它于 2014 年在Airbnb启动开源项目，以帮助公司处理其批量数据管道。自那时起，它已成为数据工程中最受欢迎的开源工作流管理平台之一。 Apache Airflow是用 Python 书写的，它具有灵活性和稳健性。其强大且设备齐全的用户界面简化了工作流</description>
    </item>
    <item>
      <title>BI-数据仓-初学者数据仓库教程：学习基本概念</title>
      <link>https://geek.zshipu.com/post/bi/%E5%A4%A7%E6%95%B0%E6%8D%AE/BI-%E6%95%B0%E6%8D%AE%E4%BB%93-%E5%88%9D%E5%AD%A6%E8%80%85%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%95%99%E7%A8%8B%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</link>
      <pubDate>Sun, 24 Oct 2021 19:30:00 +0000</pubDate>
      <guid>https://geek.zshipu.com/post/bi/%E5%A4%A7%E6%95%B0%E6%8D%AE/BI-%E6%95%B0%E6%8D%AE%E4%BB%93-%E5%88%9D%E5%AD%A6%E8%80%85%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E6%95%99%E7%A8%8B%E5%AD%A6%E4%B9%A0%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/</guid>
      <description>数据仓库教程摘要 数据仓库是软件工具的集合，帮助分析大量不同的数据。目标是从数据中获取有利可图的见解。本课程涵盖数据市场、数据湖、舍马斯等高级主题。 我应该知道些什么？ 教程专为几乎没有或根本没有数据仓库体验的初学者设计。虽然对数据库和SQL的基本理解是一个优势。 数据仓库课程教学大纲 介</description>
    </item>
    <item>
      <title>BI-数据湖-什么是数据湖 它是建筑-数据湖教程</title>
      <link>https://geek.zshipu.com/post/bi/%E5%A4%A7%E6%95%B0%E6%8D%AE/BI-%E6%95%B0%E6%8D%AE%E6%B9%96-%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E6%B9%96-%E5%AE%83%E6%98%AF%E5%BB%BA%E7%AD%91-%E6%95%B0%E6%8D%AE%E6%B9%96%E6%95%99%E7%A8%8B/</link>
      <pubDate>Sun, 24 Oct 2021 19:20:00 +0000</pubDate>
      <guid>https://geek.zshipu.com/post/bi/%E5%A4%A7%E6%95%B0%E6%8D%AE/BI-%E6%95%B0%E6%8D%AE%E6%B9%96-%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E6%B9%96-%E5%AE%83%E6%98%AF%E5%BB%BA%E7%AD%91-%E6%95%B0%E6%8D%AE%E6%B9%96%E6%95%99%E7%A8%8B/</guid>
      <description>什么是数据湖？ 数据湖是一个存储库，可以存储大量的结构化、半结构化和非结构化数据。它是以本地格式存储每种类型数据的地方，对帐户大小或文件没有固定限制。它提供高数据量，以提高分析性能和本地集成。 数据湖就像一个大容器，非常类似于真正的湖泊和河流。就像在一个湖中，你有多个支流进来，一个数</description>
    </item>
    <item>
      <title>BI-数据湖-一文看懂数据湖：概念、特征、架构与案例</title>
      <link>https://geek.zshipu.com/post/bi/%E5%A4%A7%E6%95%B0%E6%8D%AE/BI-%E6%95%B0%E6%8D%AE%E6%B9%96-%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82%E6%95%B0%E6%8D%AE%E6%B9%96%E6%A6%82%E5%BF%B5%E7%89%B9%E5%BE%81%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%A1%88%E4%BE%8B/</link>
      <pubDate>Sun, 24 Oct 2021 19:10:00 +0000</pubDate>
      <guid>https://geek.zshipu.com/post/bi/%E5%A4%A7%E6%95%B0%E6%8D%AE/BI-%E6%95%B0%E6%8D%AE%E6%B9%96-%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82%E6%95%B0%E6%8D%AE%E6%B9%96%E6%A6%82%E5%BF%B5%E7%89%B9%E5%BE%81%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%A1%88%E4%BE%8B/</guid>
      <description>什么是数据湖； 数据湖的基本特征； 数据湖基本架构； 各厂商的数据湖解决方案； 典型的数据湖应用场景； 数据湖建设的基本过程； 总结。 一、什么是数据湖 数据湖是目前比较热的一个概念，许多企业都在构建或者计划构建自己的数据湖。但是在计划构建数据湖之前，搞清楚什么是数据湖，明确一个数据湖项目的基本</description>
    </item>
    <item>
      <title>BI-MongoDB-中台MongoDB应用</title>
      <link>https://geek.zshipu.com/post/bi/%E5%A4%A7%E6%95%B0%E6%8D%AE/BI-MongoDB-%E4%B8%AD%E5%8F%B0MongoDB%E5%BA%94%E7%94%A8/</link>
      <pubDate>Sun, 24 Oct 2021 19:00:00 +0000</pubDate>
      <guid>https://geek.zshipu.com/post/bi/%E5%A4%A7%E6%95%B0%E6%8D%AE/BI-MongoDB-%E4%B8%AD%E5%8F%B0MongoDB%E5%BA%94%E7%94%A8/</guid>
      <description>目前数据仓库与大数据 不足 数据中台 以打通部门或数据孤岛的统一数据平台为基础，构建统一数据资产体系，并以API服务方式为全渠道业务 分析+应用，提供即时交付能力的企业级数据架构 金融行业 ](https://img202 技术需求 技术产品 关系型数据库 数据仓库 大数据 NOSQL与非结构数据 MongoDb存储的优势，多模数据库</description>
    </item>
    <item>
      <title>Metabase教程系列-设置电子邮件</title>
      <link>https://geek.zshipu.com/post/bi/%E5%8F%AF%E8%A7%86%E5%8C%96/Metabase%E6%95%99%E7%A8%8B%E7%B3%BB%E5%88%97-%E8%AE%BE%E7%BD%AE%E7%94%B5%E5%AD%90%E9%82%AE%E4%BB%B6/</link>
      <pubDate>Sun, 24 Oct 2021 18:11:00 +0000</pubDate>
      <guid>https://geek.zshipu.com/post/bi/%E5%8F%AF%E8%A7%86%E5%8C%96/Metabase%E6%95%99%E7%A8%8B%E7%B3%BB%E5%88%97-%E8%AE%BE%E7%BD%AE%E7%94%B5%E5%AD%90%E9%82%AE%E4%BB%B6/</guid>
      <description>一旦您将数据库连接到 Metabase，您就会想要配置一个电子邮件帐户，以便向组织的用户发送系统通知。Metabase 使用电子邮件重置密码，将新用户放到船上，并在发生某些事情时通知您。 配置您的电子邮件帐户 要使 Metabase 向组织用户发送消息，您需要设置一个电子邮件帐户，以便通过*SMTP（*简</description>
    </item>
    <item>
      <title>Metabase教程系列-获取有关问题的警报</title>
      <link>https://geek.zshipu.com/post/bi/%E5%8F%AF%E8%A7%86%E5%8C%96/Metabase%E6%95%99%E7%A8%8B%E7%B3%BB%E5%88%97-%E8%8E%B7%E5%8F%96%E6%9C%89%E5%85%B3%E9%97%AE%E9%A2%98%E7%9A%84%E8%AD%A6%E6%8A%A5/</link>
      <pubDate>Sun, 24 Oct 2021 18:10:00 +0000</pubDate>
      <guid>https://geek.zshipu.com/post/bi/%E5%8F%AF%E8%A7%86%E5%8C%96/Metabase%E6%95%99%E7%A8%8B%E7%B3%BB%E5%88%97-%E8%8E%B7%E5%8F%96%E6%9C%89%E5%85%B3%E9%97%AE%E9%A2%98%E7%9A%84%E8%AD%A6%E6%8A%A5/</guid>
      <description>无论您是跟踪收入、用户还是负面评论，您经常会想提醒某些事情。Metabase 有几个不同类型的警报，您可以设置，您可以选择通过电子邮件或 Slack 收到通知。 获取警报 要开始使用警报，您团队中作为管理员的人员需要确保这一点电子邮件集成首先设置。 警报类型 在元基地中，您可以收到三种注意事项： 当时间</description>
    </item>
    <item>
      <title>Metabase教程系列-7 个您可能不知道的方便的元基础功能</title>
      <link>https://geek.zshipu.com/post/bi/%E5%8F%AF%E8%A7%86%E5%8C%96/Metabase%E6%95%99%E7%A8%8B%E7%B3%BB%E5%88%97-7-%E4%B8%AA%E6%82%A8%E5%8F%AF%E8%83%BD%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84%E6%96%B9%E4%BE%BF%E7%9A%84%E5%85%83%E5%9F%BA%E7%A1%80%E5%8A%9F%E8%83%BD/</link>
      <pubDate>Sun, 24 Oct 2021 13:00:00 +0000</pubDate>
      <guid>https://geek.zshipu.com/post/bi/%E5%8F%AF%E8%A7%86%E5%8C%96/Metabase%E6%95%99%E7%A8%8B%E7%B3%BB%E5%88%97-7-%E4%B8%AA%E6%82%A8%E5%8F%AF%E8%83%BD%E4%B8%8D%E7%9F%A5%E9%81%93%E7%9A%84%E6%96%B9%E4%BE%BF%E7%9A%84%E5%85%83%E5%9F%BA%E7%A1%80%E5%8A%9F%E8%83%BD/</guid>
      <description>Metabase 的界面试图远离您的方式，以帮助将您的数据带到最前沿。这种悠闲的方法意味着有时功能可能需要时间来发现，因此我们整理了一些您可能尚未利用的功能列表。 1. 警报：当指标达到某个数字时，会收到通知 有些人错过了问题右下角的菜单（图1）： *图1。*单击问题右下角的铃来设置警报。 他们不点击铃声，</description>
    </item>
    <item>
      <title>Metabase教程系列-基本设置</title>
      <link>https://geek.zshipu.com/post/bi/%E5%8F%AF%E8%A7%86%E5%8C%96/Metabase%E6%95%99%E7%A8%8B%E7%B3%BB%E5%88%97-%E5%9F%BA%E6%9C%AC%E8%AE%BE%E7%BD%AE/</link>
      <pubDate>Wed, 20 Oct 2021 18:00:00 +0000</pubDate>
      <guid>https://geek.zshipu.com/post/bi/%E5%8F%AF%E8%A7%86%E5%8C%96/Metabase%E6%95%99%E7%A8%8B%E7%B3%BB%E5%88%97-%E5%9F%BA%E6%9C%AC%E8%AE%BE%E7%BD%AE/</guid>
      <description>一、写在前面 概述：Metabase可以帮助你把数据库中的数据更好的呈现给更多人，数据分析人员通过建立一个”查询“（Metabase中定义为Question）来提炼数据，再通过仪表盘（Dashboards）来组合展示给公司成员 优点：1.开源免费 2.工具轻量、安装依赖的环境简单、配置</description>
    </item>
  </channel>
</rss>
