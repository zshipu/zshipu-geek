<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>中文分词 on 知识铺的博客</title>
    <link>https://geek.zshipu.com/tags/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D/</link>
    <description>Recent content in 中文分词 on 知识铺的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 15 Mar 2022 11:26:55 +0800</lastBuildDate>
    <atom:link href="https://geek.zshipu.com/tags/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>干货中文分词技术详解</title>
      <link>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E5%B9%B2%E8%B4%A7%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3/</link>
      <pubDate>Tue, 15 Mar 2022 11:26:55 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E5%B9%B2%E8%B4%A7%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3/</guid>
      <description>作者：李rumor 虽然现在大家都用字粒度的BERT隐式地进行词法分析，但分词依旧是很多系统中重要的一环，BERT之前的经典浅层模型大都以词向量作为输入。今天就再把分词拿出来聊聊，如果有一天大家做了面试官，不妨把这些细节拿出来问一哈。 NLP的底层任务由易到难大致可以分为词法分析、句</description>
    </item>
    <item>
      <title>中文分词技术及在搜索的实践</title>
      <link>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%8A%80%E6%9C%AF%E5%8F%8A%E5%9C%A8%E6%90%9C%E7%B4%A2%E7%9A%84%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Tue, 15 Mar 2022 01:29:08 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E6%8A%80%E6%9C%AF%E5%8F%8A%E5%9C%A8%E6%90%9C%E7%B4%A2%E7%9A%84%E5%AE%9E%E8%B7%B5/</guid>
      <description>文本、语言作为记录和传播信息的重要载体，对它高效的理解一直是人们关注的问题。自现代电子计算机出现后，计算机在很多事情上做得比人还好，计算机与语言处理的相遇就出现了自然语言处理（Natural Language Process, NLP）技术。NLP通俗的理解就是利用计算机对文本进行分析、加工。 中文语言处理则是针对</description>
    </item>
    <item>
      <title>深度长文中文分词的十年回顾</title>
      <link>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E6%B7%B1%E5%BA%A6%E9%95%BF%E6%96%87%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E7%9A%84%E5%8D%81%E5%B9%B4%E5%9B%9E%E9%A1%BE/</link>
      <pubDate>Mon, 14 Mar 2022 17:43:50 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E6%B7%B1%E5%BA%A6%E9%95%BF%E6%96%87%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E7%9A%84%E5%8D%81%E5%B9%B4%E5%9B%9E%E9%A1%BE/</guid>
      <description>_本文作者：上海交通大学赵海、蔡登，清华大学黄昌宁，香港城市大学揭春雨 _ 转载请联系原作者 本文回顾了 中文分词 在2007-2017十年间的技术进展，尤其是自 深度学习渗透到自然语言处理 以来的主要工作。我们的基本结论是，中文分词的监督机器学习方法在从非神经网络方法到神经网络方法的迁移中尚</description>
    </item>
  </channel>
</rss>
