<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Softmax on 知识铺的博客</title>
    <link>https://geek.zshipu.com/tags/Softmax/</link>
    <description>Recent content in Softmax on 知识铺的博客</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Tue, 15 Mar 2022 03:20:40 +0800</lastBuildDate>
    <atom:link href="https://geek.zshipu.com/tags/Softmax/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>干货函数详解</title>
      <link>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E5%B9%B2%E8%B4%A7%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/</link>
      <pubDate>Tue, 15 Mar 2022 03:20:40 +0800</pubDate>
      <guid>https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E5%B9%B2%E8%B4%A7%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3/</guid>
      <description>阅读原文 发表于： 2019-08-24 0. 引言 Softmax 函数几乎是深度学习中的标配了， 在人工神经网络中，几乎无处不可见 softmax 函数的身影。可以认为 softmax 是 arg max 操作的一种平滑近似。 我将 softmax 的用途总结为两种： 分类：给定一系列类别，softmax 可以给出某输入被划分到各个类别的概率分布。由于人工智能领域的许多问题都可以抽象成分</description>
    </item>
  </channel>
</rss>
