<!doctype html>
<html lang="zh-CN">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>万字长文梳理预估模型发展过程与关系图谱 | 知识铺的博客</title>
    <meta property="og:title" content="万字长文梳理预估模型发展过程与关系图谱 - 知识铺的博客">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content='2022-03-15T09:06:45&#43;08:00'>
        
        
    <meta property="article:modified_time" content='2022-03-15T09:06:45&#43;08:00'>
        
    <meta name="Keywords" content="golang,go语言,go语言笔记,知识铺,java,android,博客,项目管理,python,软件架构,公众号,小程序">
    <meta name="description" content="万字长文梳理预估模型发展过程与关系图谱">
        <meta name="author" content="知识铺">
        
    <meta property="og:url" content="https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E4%B8%87%E5%AD%97%E9%95%BF%E6%96%87%E6%A2%B3%E7%90%86%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95%E8%BF%87%E7%A8%8B%E4%B8%8E%E5%85%B3%E7%B3%BB%E5%9B%BE%E8%B0%B1/">
    <link rel="shortcut icon" href='/favicon.ico'  type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    <script data-ad-client="ca-pub-2874221941555456" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    
    
    
    
    
    
    
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-WLWJSST');</script>
    
</head>


<body>

<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WLWJSST"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://geek.zshipu.com/">
                        知识铺的博客
                    </a>
                
                <p class="description">专注于Android、Java、Go语言(golang)、移动互联网、项目管理、软件架构</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="current" href="https://geek.zshipu.com/">首页</a>
                    
                    <a  href="https://geek.zshipu.com/archives/" title="归档">归档</a>
                    
                    <a  href="https://geek.zshipu.com/about/" title="关于">关于</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    <style type="text/css">
    .post-toc {
        position: fixed;
        width: 200px;
        margin-left: -210px;
        padding: 5px 10px;
        font-family: Athelas, STHeiti, Microsoft Yahei, serif;
        font-size: 12px;
        border: 1px solid rgba(0, 0, 0, .07);
        border-radius: 5px;
        background-color: rgba(255, 255, 255, 0.98);
        background-clip: padding-box;
        -webkit-box-shadow: 1px 1px 2px rgba(0, 0, 0, .125);
        box-shadow: 1px 1px 2px rgba(0, 0, 0, .125);
        word-wrap: break-word;
        white-space: nowrap;
        -webkit-box-sizing: border-box;
        box-sizing: border-box;
        z-index: 999;
        cursor: pointer;
        max-height: 70%;
        overflow-y: auto;
        overflow-x: hidden;
    }

    .post-toc .post-toc-title {
        width: 100%;
        margin: 0 auto;
        font-size: 20px;
        font-weight: 400;
        text-transform: uppercase;
        text-align: center;
    }

    .post-toc .post-toc-content {
        font-size: 15px;
    }

    .post-toc .post-toc-content>nav>ul {
        margin: 10px 0;
    }

    .post-toc .post-toc-content ul {
        padding-left: 20px;
        list-style: square;
        margin: 0.5em;
        line-height: 1.8em;
    }

    .post-toc .post-toc-content ul ul {
        padding-left: 15px;
        display: none;
    }

    @media print,
    screen and (max-width:1057px) {
        .post-toc {
            display: none;
        }
    }
</style>
<div class="post-toc" style="position: absolute; top: 188px;">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
        <nav id="TableOfContents">
  <ul>
    <li><a href="#背景">背景</a></li>
    <li><a href="#目录">目录</a></li>
    <li><a href="#一-分布式线性模型">一。 分布式线性模型</a>
      <ul>
        <li><a href="#logistic-regression">Logistic Regression</a></li>
      </ul>
    </li>
    <li><a href="#二-自动化特征工程">二。 自动化特征工程</a>
      <ul>
        <li><a href="#gbdt--lr2014-特征自动化时代的初探索">GBDT + LR（2014）—— 特征自动化时代的初探索</a></li>
      </ul>
    </li>
    <li><a href="#三-fm-模型以及变体">三。 FM 模型以及变体</a>
      <ul>
        <li><a href="#1fmfactorization-machines-2010--隐向量学习提升模型表达">（1）FM：Factorization Machines, 2010 —— 隐向量学习提升模型表达</a></li>
        <li><a href="#不足">不足：</a></li>
        <li><a href="#2afmattentional-factorization-machines-2017--引入-attention-机制的-fm">（2）AFM：Attentional Factorization Machines, 2017 —— 引入 Attention 机制的 FM</a></li>
      </ul>
    </li>
    <li><a href="#四-embeddingmlp-结构下的浅层改造">四。 Embedding+MLP 结构下的浅层改造</a>
      <ul>
        <li><a href="#1fnn-factorisation-machine-supported-neural-network-2016--预训练-embedding-的-nn-模型">（1）FNN： Factorisation Machine supported Neural Network, 2016 —— 预训练 Embedding 的 NN 模型</a></li>
        <li><a href="#2pnnproduct-based-neural-network-2016--引入不同-product-操作的-embedding-层">（2）PNN：Product-based Neural Network, 2016 —— 引入不同 Product 操作的 Embedding 层</a></li>
        <li><a href="#3nfmneural-factorization-machines-2017--引入-bi-interaction-pooling-结构的-nn-模型">（3）NFM：Neural Factorization Machines, 2017 —— 引入 Bi-Interaction Pooling 结构的 NN 模型</a></li>
        <li><a href="#4onnoperation-aware-neural-network-2019--ffm-与-nn-的结合体"><strong>（4）ONN：Operation-aware Neural Network, 2019 —— FFM 与 NN 的结合体</strong></a></li>
      </ul>
    </li>
    <li><a href="#五-双路并行的模型组合">五。 双路并行的模型组合</a>
      <ul>
        <li><a href="#1wdlwide-and-deep-learning-2016--memorization-与-generalization-的信息互补">（1）WDL：Wide and Deep Learning, 2016 —— Memorization 与 Generalization 的信息互补</a></li>
        <li><a href="#不足-1">不足：</a></li>
        <li><a href="#2deepfmdeep-factorization-machines-2017--fm-基础上引入-nn-隐式高阶交叉信息"><strong>（2）DeepFM：Deep Factorization Machines, 2017 —— FM 基础上引入 NN 隐式高阶交叉信息</strong></a></li>
      </ul>
    </li>
    <li><a href="#六-复杂的显式特征交叉网络">六。 复杂的显式特征交叉网络</a>
      <ul>
        <li><a href="#1deepcrossdeep-and-cross-network-2017--显式交叉网络-cross-net-的诞生">（1）Deep&amp;Cross：Deep and Cross Network, 2017 —— 显式交叉网络 Cross Net 的诞生</a></li>
        <li><a href="#2xdeepfmextreme-deep-factorization-machine-2018--compressed-interaction-network-的诞生">**（2）xDeepFM：**eXtreme Deep Factorization Machine, 2018 —— <strong>Compressed Interaction Network 的诞生</strong></a></li>
        <li><a href="#3autointautomatic-feature-interaction-learning-2019--跨领域-nlp-技术的引入multi-head-self-attention-提升模型表达">（3）AutoInt：Automatic Feature Interaction Learning, 2019 —— 跨领域 NLP 技术的引入：Multi-head Self-attention 提升模型表达</a></li>
      </ul>
    </li>
    <li><a href="#七-ctr-预估模型总结与比较">七。 CTR 预估模型总结与比较</a>
      <ul>
        <li><a href="#1ctr-预估模型关系图谱">（1）CTR 预估模型关系图谱</a></li>
        <li><a href="#2ctr-预估模型特性对比">（2）CTR 预估模型特性对比</a></li>
      </ul>
    </li>
    <li><a href="#结语">结语</a></li>
  </ul>
</nav>
    </div>
</div>
<script type="text/javascript">
    $(document).ready(function () {
        var postToc = $(".post-toc");
        if (postToc.length) {
            var leftPos = $("#main").offset().left;
            if(leftPos<220){
                postToc.css({"width":leftPos-10,"margin-left":(0-leftPos)})
            }

            var t = postToc.offset().top - 20,
                a = {
                    start: {
                        position: "absolute",
                        top: t
                    },
                    process: {
                        position: "fixed",
                        top: 20
                    },
                };
            $(window).scroll(function () {
                var e = $(window).scrollTop();
                e < t ? postToc.css(a.start) : postToc.css(a.process)
            })
        }
    })
</script>
    <article class="post">
        <header>
            <h1 class="post-title">万字长文梳理预估模型发展过程与关系图谱</h1>
        </header>
        <date class="post-meta meta-date">
            2022年3月15日
        </date>
        
        
        <div class="post-meta">
            <span id="busuanzi_container_page_pv">|<span id="busuanzi_value_page_pv"></span><span>
                    阅读</span></span>
        </div>
        
        
        <div class="post-content">
            <h2 id="背景">背景</h2>
<p>在推荐、搜索、广告等领域，CTR（click-through rate）预估是一项非常核心的技术，这里引用阿里妈妈资深算法专家朱小强大佬的一句话：“它（CTR 预估）是镶嵌在互联网技术上的明珠”。</p>
<p>本篇文章主要是对 CTR 预估中的常见模型进行梳理与总结，并分成模块进行概述。每个模型都会从「模型结构」、「优势」、「不足」三个方面进行探讨，在最后对所有模型之间的关系进行比较与总结。本篇文章讨论的模型如下图所示（原创图），这个图中展示了本篇文章所要讲述的算法以及之间的关系，在文章的最后总结会对这张图进行详细地说明。</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271350976.jpeg" />   
    </p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271351326.jpeg" />   
    </p>
<h2 id="目录">目录</h2>
<p>本篇文章将会按照整个 CTR 预估模型的演进过程进行组织，共分为 7 个大部分：</p>
<ul>
<li><strong>分布式线性模型</strong>
<ul>
<li>Logistic Regression</li>
</ul>
</li>
<li><strong>自动化特征工程</strong></li>
<li>GBDT+LR</li>
<li><strong>FM 模型以及变体</strong></li>
<li>FM（Factorization Machines）</li>
<li>FFM（Field-aware Factorization Machines）</li>
<li>AFM（Attentional Factorization Machines）</li>
<li><strong>Embedding+MLP 结构下的浅层改造</strong></li>
<li>FNN（Factorization Machine supported Neural Network）</li>
<li>PNN（Product-based Neural Network）</li>
<li>NFM（Neural Factorization Machines）</li>
<li>ONN（Operation-aware Neural Networks）</li>
<li><strong>双路并行的模型组合</strong></li>
<li>wide&amp;deep（Wide and Deep）</li>
<li>deepFM（Deep Factorization Machines）</li>
<li><strong>复杂的显式特征交叉网络</strong></li>
<li>DCN（Deep and Cross Network）</li>
<li>xDeepFM（Compressed Interaction Network）</li>
<li>AutoInt（Automatic Feature Interaction Learning）</li>
<li><strong>CTR 预估模型总结与比较</strong></li>
<li>CTR 预估模型关系图谱</li>
<li>CTR 预估模型特性对比</li>
</ul>
<hr>
<h2 id="一-分布式线性模型">一。 分布式线性模型</h2>
<h3 id="logistic-regression">Logistic Regression</h3>
<p>Logistic Regression 是每一位算法工程师再也熟悉不过的基本算法之一了，毫不夸张地说，LR 作为最经典的统计学习算法几乎统治了早期工业机器学习时代。这是因为其具备简单、时间复杂度低、可大规模并行化等优良特性。在早期的 CTR 预估中，算法工程师们通过手动设计交叉特征以及特征离散化等方式，赋予 LR 这样的线性模型对数据集的非线性学习能力，高维离散特征 + 手动交叉特征构成了 CTR 预估的基础特征。LR 在工程上易于大规模并行化训练恰恰适应了这个时代的要求。</p>
<p><strong>模型结构：</strong></p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271351297.svg&#43;xml" />   
    </p>
<p><strong>优势：</strong></p>
<ul>
<li>模型简单，具备一定可解释性</li>
<li>计算时间复杂度低</li>
<li>工程上可大规模并行化</li>
</ul>
<p><strong>不足：</strong></p>
<ul>
<li>依赖于人工大量的特征工程，例如需要根据业务背知识通过特征工程融入模型</li>
<li>特征交叉难以穷尽</li>
<li>对于训练集中没有出现的交叉特征无法进行参数学习</li>
</ul>
<hr>
<h2 id="二-自动化特征工程">二。 自动化特征工程</h2>
<h3 id="gbdt--lr2014-特征自动化时代的初探索">GBDT + LR（2014）—— 特征自动化时代的初探索</h3>
<p>Facebook 在 2014 年提出了 GBDT+LR 的组合模型来进行 CTR 预估，其本质上是通过 Boosting Tree 模型本身的特征组合能力来替代原先算法工程师们手动组合特征的过程。GBDT 等这类 Boosting Tree 模型本身具备了特征筛选能力（每次分裂选取增益最大的分裂特征与分裂点）以及高阶特征组合能力（树模型天然优势），因此通过 GBDT 来自动生成特征向量就成了一个非常自然的思路。注意这里虽然是两个模型的组合，但实际并非是端到端的模型，而是两阶段的、解耦的，即先通过 GBDT 训练得到特征向量后，再作为下游 LR 的输入，LR 的在训练过程中并不会对 GBDT 进行更新。</p>
<p><strong>模型结构：</strong></p>
<p>通过 GBDT 训练模型，得到组合的特征向量。例如训练了两棵树，每棵树有 5 个叶子结点，对于某个特定样本来说，落在了第一棵树的第 3 个结点，此时我们可以得到向量

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271351320.svg&#43;xml" />   
    
；落在第二棵树的第 4 个结点，此时的到向量

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271351709.svg&#43;xml" />   
    
；那么最终通过 concat 所有树的向量，得到这个样本的最终向量

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271351983.svg&#43;xml" />   
    
。将这个向量作为下游 LR 模型的 inputs，进行训练。</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271351188.jpeg" />   
    </p>
<p><strong>优势：</strong></p>
<ul>
<li>特征工程自动化，通过 Boosting Tree 模型的天然优势自动探索特征组合</li>
</ul>
<p><strong>不足：</strong></p>
<ul>
<li>两阶段的、非端到端的模型</li>
<li>CTR 预估场景涉及到大量高维稀疏特征，树模型并不适合处理（因此实际上会将 dense 特征或者低维的离散特征给 GBDT，剩余高维稀疏特征在 LR 阶段进行训练）</li>
<li>GBDT 模型本身比较复杂，无法做到 online learning，模型对数据的感知相对较滞后（必须提高离线模型的更新频率）</li>
</ul>
<hr>
<h2 id="三-fm-模型以及变体">三。 FM 模型以及变体</h2>
<h3 id="1fmfactorization-machines-2010--隐向量学习提升模型表达">（1）FM：Factorization Machines, 2010 —— 隐向量学习提升模型表达</h3>
<p>FM 是在 2010 年提出的一种可以学习二阶特征交叉的模型，通过在原先线性模型的基础上，枚举了所有特征的二阶交叉信息后融入模型，提高了模型的表达能力。但不同的是，模型在二阶交叉信息的权重学习上，采用了隐向量内积（也可看做 embedding）的方式进行学习。</p>
<p><strong>模型结构：</strong></p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271351143.jpeg" />   
    </p>
<p>FM 的公式包含了一阶线性部分与二阶特征交叉部分：</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271351714.svg&#43;xml" />   
    </p>
<p>在 LR 中，一般是通过手动构造交叉特征后，喂给模型进行训练，例如我们构造性别与广告类别的交叉特征：

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271351215.svg&#43;xml" />   
    
(gender=&lsquo;女&rsquo; &amp; ad_category=&lsquo;美妆&rsquo;)，此时我们会针对这个交叉特征学习一个参数

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271351646.svg&#43;xml" />   
    
。但是在 LR 中，参数梯度更新公式与该特征取值

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271352867.svg&#43;xml" />   
    
关系密切：

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271352180.svg&#43;xml" />   
    
，当

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271352417.svg&#43;xml" />   
    
取值为 0 时，参数

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271352670.svg&#43;xml" />   
    
就无法得到更新，而

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271352961.svg&#43;xml" />   
    
要非零就要求交叉特征的两项都要非零，但实际在数据高度稀疏，一旦两个特征只要有一个取 0，参数

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271352238.svg&#43;xml" />   
    
不能得到有效更新；除此之外，对于训练集中没有出现的交叉特征，也没办法学习这类权重，泛化性能不够好。</p>
<p>另外，在 FM 中通过将特征隐射到 k 维空间求内积的方式，打破了交叉特征权重间的隔离性（break the independence of the interaction parameters），增加模型在稀疏场景下学习交叉特征的能力。一个交叉特征参数的估计，可以帮助估计其他相关的交叉特征参数。例如，假设我们有交叉特征 gender=male &amp; movie_genre=war，我们需要估计这个交叉特征前的参数

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271352570.svg&#43;xml" />   
    
，FM 通过将

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271352019.svg&#43;xml" />   
    
分解为

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271352379.svg&#43;xml" />   
    
的方式进行估计，那么对于每次更新 male 或者 war 的隐向量

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271352595.svg&#43;xml" />   
    
时，都会影响其他与 male 或者 war 交叉的特征参数估计，使得特征权重的学习不再互相独立。这样做的好处是，对于 traindata set 中没有出现过的交叉特征，FM 仍然可以给到一个较好的非零预估值。</p>
<p><strong>优势：</strong></p>
<ul>
<li>可以有效处理稀疏场景下的特征学习</li>
<li>具有线性时间复杂度（化简思路：

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271352870.svg&#43;xml" />   
    
）</li>
<li>对训练集中未出现的交叉特征信息也可进行泛化</li>
</ul>
<h3 id="不足">不足：</h3>
<ul>
<li>2-way 的 FM 仅枚举了所有特征的二阶交叉信息，没有考虑高阶特征的信息</li>
</ul>
<blockquote>
<p>FFM（Field-aware Factorization Machine）是 Yuchin Juan 等人在 2015 年的比赛中提出的一种对 FM 改进算法，主要是引入了 field 概念，即认为每个 feature 对于不同 field 的交叉都有不同的特征表达。FFM 相比于 FM 的计算时间复杂度更高，但同时也提高了本身模型的表达能力。FM 也可以看成只有一个 field 的 FFM，这里不做过多赘述。</p>
</blockquote>
<h3 id="2afmattentional-factorization-machines-2017--引入-attention-机制的-fm">（2）AFM：Attentional Factorization Machines, 2017 —— 引入 Attention 机制的 FM</h3>
<p>AFM 全称 Attentional Factorization Machines，顾名思义就是引入 Attention 机制的 FM 模型。我们知道 FM 模型枚举了所有的二阶交叉特征（second-order interactions），即

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271353364.svg&#43;xml" />   
    
，实际上有一些交叉特征可能与我们的预估目标关联性不是很大；AFM 就是通过 Attention 机制来学习不同二阶交叉特征的重要性（这个思路与 FFM 中不同 field 特征交叉使用不同的 embedding 实际上是一致的，都是通过引入额外信息来表达不同特征交叉的重要性）。</p>
<p>举例来说，在预估用户是否会点击广告时，我们假设有用户性别、广告版位尺寸大小、广告类型三个特征，分别对应三个 embedding：

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271353572.svg&#43;xml" />   
    
，

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271353004.svg&#43;xml" />   
    
，

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271353377.svg&#43;xml" />   
    
，对于用户“是否点击”这一目标

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271353706.svg&#43;xml" />   
    
来说，显然性别与 ad_size 的交叉特征对于

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271353905.svg&#43;xml" />   
    
的相关度不大，但性别与 ad_category 的交叉特征（如 gender= 女性&amp;category= 美妆）就会与

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271353126.svg&#43;xml" />   
    
更加相关；换句话说，我们认为当性别与 ad_category 交叉时，重要性应该要高于性别与 ad_size 的交叉；FFM 中通过引入 Field-aware 的概念来量化这种与不同特征交叉时的重要性，AFM 则是通过加入 Attention 机制，赋予重要交叉特征更高的重要性。</p>
<p><strong>模型结构：</strong></p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271353624.jpeg" />   
    </p>
<p>AFM 在 FM 的二阶交叉特征上引入 Attention 权重，公式如下：</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271353605.svg&#43;xml" />   
    </p>
<blockquote>
<p>其中

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271353970.svg&#43;xml" />   
    
代表 element-wise 的向量相乘，下同。</p>
</blockquote>
<p>其中，

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271354722.svg&#43;xml" />   
    
是模型所学习到的

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271354008.svg&#43;xml" />   
    
与

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271354306.svg&#43;xml" />   
    
特征交叉的重要性，其公式如下：</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271354717.svg&#43;xml" />   
    </p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271354193.svg&#43;xml" />   
    </p>
<p>我们可以看到这里的权重

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271354444.svg&#43;xml" />   
    
实际是通过输入

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271354566.svg&#43;xml" />   
    
和

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271354961.svg&#43;xml" />   
    
训练了一个一层隐藏层的 NN 网络，让模型自行去学习这个权重。</p>
<p>对比 AFM 和 FM 的公式我们可以发现，AFM 实际上是 FM 的更加泛化的一种形式。当我们令向量

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271354558.svg&#43;xml" />   
    
，权重

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271354053.svg&#43;xml" />   
    
时，AFM 就会退化成 FM 模型。</p>
<p><strong>优势：</strong></p>
<ul>
<li>在 FM 的二阶交叉项上引入 Attention 机制，赋予不同交叉特征不同的重要度，增加了模型的表达能力</li>
<li>Attention 的引入，一定程度上增加了模型的可解释性</li>
</ul>
<p><strong>不足：</strong></p>
<ul>
<li>仍然是一种浅层模型，模型没有学习到高阶的交叉特征</li>
</ul>
<hr>
<h2 id="四-embeddingmlp-结构下的浅层改造">四。 Embedding+MLP 结构下的浅层改造</h2>
<p>本章所介绍的都是具备 Embedding+MLP 这样结构的模型，之所以称作浅层改造，主要原因在于这些模型都是在 embedding 层进行的一些改变，例如 FNN 的预训练 Embedding、PNN 的 Product layer、NFM 的 Bi-Interaction Layer 等等，这些改变背后的思路可以归纳为：使用复杂的操作让模型在浅层尽可能包含更多的信息，降低后续下游 MLP 的学习负担。</p>
<h3 id="1fnn-factorisation-machine-supported-neural-network-2016--预训练-embedding-的-nn-模型">（1）FNN： Factorisation Machine supported Neural Network, 2016 —— 预训练 Embedding 的 NN 模型</h3>
<p>FNN 是 2016 年提出的一种基于 FM 预训练 Embedding 的 NN 模型，其思路也比较简单；FM 本身具备学习特征 Embedding 的能力，DNN 具备高阶特征交叉的能力，因此将两者结合是很直接的思路。FM 预训练的 Embedding 可以看做是“先验专家知识”，直接将专家知识输入 NN 来进行学习。注意，FNN 本质上也是两阶段的模型，与 Facebook 在 2014 年提出 GBDT+LR 模型在思想上一脉相承。</p>
<p><strong>模型结构：</strong></p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271354669.jpeg" />   
    </p>
<p>FNN 本身在结构上并不复杂，如上图所示，就是将 FM 预训练好的 Embedding 向量直接喂给下游的 DNN 模型，让 DNN 来进行更高阶交叉信息的学习。</p>
<p><strong>优势：</strong></p>
<ul>
<li>离线训练 FM 得到 embedding，再输入 NN，相当于引入先验专家经验</li>
<li>加速模型的训练和收敛</li>
<li>NN 模型省去了学习 feature embedding 的步骤，训练开销低</li>
</ul>
<p><strong>不足：</strong></p>
<ul>
<li>非端到端的两阶段模型，不利于 online learning</li>
<li>预训练的 Embedding 受到 FM 模型的限制</li>
<li>FNN 中只考虑了特征的高阶交叉，并没有保留低阶特征信息</li>
</ul>
<h3 id="2pnnproduct-based-neural-network-2016--引入不同-product-操作的-embedding-层">（2）PNN：Product-based Neural Network, 2016 —— 引入不同 Product 操作的 Embedding 层</h3>
<p>PNN 是 2016 年提出的一种在 NN 中引入 Product Layer 的模型，其本质上和 FNN 类似，都属于 Embedding+MLP 结构。作者认为，在 DNN 中特征 Embedding 通过简单的 concat 或者 add 都不足以学习到特征之间复杂的依赖信息，因此 PNN 通过引入 Product Layer 来进行更复杂和充分的特征交叉关系的学习。PNN 主要包含了 IPNN 和 OPNN 两种结构，分别对应特征之间 Inner Product 的交叉计算和 Outer Product 的交叉计算方式。</p>
<p><strong>模型结构：</strong></p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271355814.jpeg" />   
    </p>
<p>PNN 结构显示通过 Embedding Lookup 得到每个 field 的 Embedding 向量，接着将这些向量输入 Product Layer，在 Product Layer 中包含了两部分，一部分是左边的

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271355629.svg&#43;xml" />   
    
，就是将特征原始的 Embedding 向量直接保留；另一部分是右侧的

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271355833.svg&#43;xml" />   
    
，即对应特征之间的 product 操作；可以看到 PNN 相比于 FNN 一个优势就是保留了原始的低阶 embedding 特征。</p>
<p>在 PNN 中，由于引入 Product 操作，会使模型的时间和空间复杂度都进一步增加。这里以 IPNN 为例，其中

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271355330.svg&#43;xml" />   
    
是 pair-wise 的特征交叉向量，假设我们共有 N 个特征，每个特征的 embedding 信息

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271355850.svg&#43;xml" />   
    
；在 Inner Product 的情况下，通过交叉项公式

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271355462.svg&#43;xml" />   
    
会得到

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271355766.svg&#43;xml" />   
    
（其中

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271355007.svg&#43;xml" />   
    
是对称矩阵），此时从 Product 层到

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271355290.svg&#43;xml" />   
    
层（假设

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271355665.svg&#43;xml" />   
    
层有

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271355528.svg&#43;xml" />   
    
个结点），对于

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271355230.svg&#43;xml" />   
    
层的每个结点我们有：

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271356494.svg&#43;xml" />   
    
，因此这里从 product layer 到 L1 层参数空间复杂度为

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271356046.svg&#43;xml" />   
    
；作者借鉴了 FM 的思想对参数

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271356413.svg&#43;xml" />   
    
进行了矩阵分解：

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271356897.svg&#43;xml" />   
    
，此时 L1 层每个结点的计算可以化简为：

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271356112.svg&#43;xml" />   
    
，空间复杂度退化

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271356327.svg&#43;xml" />   
    
。</p>
<p><strong>优势：</strong></p>
<ul>
<li>PNN 通过

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271356605.svg&#43;xml" />   
    
保留了低阶 Embedding 特征信息</li>
<li>通过 Product Layer 引入更复杂的特征交叉方式，</li>
</ul>
<p><strong>不足：</strong></p>
<ul>
<li>计算时间复杂度相对较高</li>
</ul>
<h3 id="3nfmneural-factorization-machines-2017--引入-bi-interaction-pooling-结构的-nn-模型">（3）NFM：Neural Factorization Machines, 2017 —— 引入 Bi-Interaction Pooling 结构的 NN 模型</h3>
<p>NFM 全程为 Neural Factorization Machines，它与 FNN 一样，都属于将 FM 与 NN 进行结合的模型。但不同的是 NFM 相比于 FNN 是一种端到端的模型。NFM 与 PNN 也有很多相似之出，本质上也属于 Embedding+MLP 结构，只是在浅层的特征交互上采用了不同的结构。NFM 将 PNN 的 Product Layer 替换成了 Bi-interaction Pooling 结构来进行特征交叉的学习。</p>
<p><strong>模型结构：</strong></p>
<p>NFM 的整个模型公式为：</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271356408.svg&#43;xml" />   
    </p>
<p>其中

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271356749.svg&#43;xml" />   
    
是 Bi-Interaction Pooling+NN 部分的输出结果。我们重点关注 NFM 中的 Bi-Interaction Pooling 层：

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271356496.jpeg" />   
    </p>
<p>NFM 的结构如上图所示，通过对特征 Embedding 之后，进入 Bi-Interaction Pooling 层。这里注意一个小细节，NFM 的对 Dense Feature，Embedding 方式于 AFM 相同，将 Dense Feature Embedding 以后再用 dense feature 原始的数据进行了 scale，即

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271357173.svg&#43;xml" />   
    
。</p>
<p>NFM 的 Bi-Interaction Pooling 层是对两两特征的 embedding 进行 element-wise 的乘法，公式如下：</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271357006.svg&#43;xml" />   
    </p>
<p>假设我们每个特征 Embedding 向量的维度为

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271357059.svg&#43;xml" />   
    
，则

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271357489.svg&#43;xml" />   
    
，Bi-Interaction Pooling 的操作简单来说就是将所有二阶交叉的结果向量进行 sum pooling 后再送入 NN 进行训练。对比 AFM 的 Attention 层，Bi-Interaction Pooling 层采用直接 sum 的方式，缺少了 Attention 机制；对比 FM 莫明星，NFM 如果将后续 DNN 隐藏层删掉，就会退化为一个 FM 模型。</p>
<blockquote>
<p>NFM 在输入层以及 Bi-Interaction Pooling 层后都引入了 BN 层，也加速了模型了收敛。</p>
</blockquote>
<p><strong>优势：</strong></p>
<ul>
<li>相比于 Embedding 的 concat 操作，NFM 在 low level 进行 interaction 可以提高模型的表达能力</li>
<li>具备一定高阶特征交叉的能力</li>
<li>Bi-Interaction Pooling 的交叉具备线性计算时间复杂度</li>
</ul>
<p><strong>不足：</strong></p>
<ul>
<li>直接进行 sum pooling 操作会损失一定的信息，可以参考 AFM 引入 Attention</li>
</ul>
<h3 id="4onnoperation-aware-neural-network-2019--ffm-与-nn-的结合体"><strong>（4）ONN：Operation-aware Neural Network, 2019 —— FFM 与 NN 的结合体</strong></h3>
<p>ONN 是 2019 年发表的 CTR 预估，我们知道 PNN 通过引入不同的 Product 操作来进行特征交叉，ONN 认为针对不同的特征交叉操作，应该用不同的 Embedding，如果用同样的 Embedding，那么各个不同操作之间就会互相影响而最终限制了模型的表达。</p>
<p>我们会发现 ONN 的思路在本质上其实和 FFM、AFM 都有异曲同工之妙，这三个模型都是通过引入了额外的信息来区分不同 field 之间的交叉应该具备不同的信息表达。总结下来：</p>
<ul>
<li>FFM：引入 Field-aware，对于 field a 来说，与 field b 交叉和 field c 交叉应该用不同的 embedding</li>
<li>AFM：引入 Attention 机制，a 与 b 的交叉特征重要度与 a 与 c 的交叉重要度不同</li>
<li>ONN：引入 Operation-aware，a 与 b 进行内积所用的 embedding，不同于 a 与 b 进行外积用的 embedding</li>
</ul>
<p>对比上面三个模型，本质上都是给模型增加更多的表达能力，个人觉得 ONN 就是 FFM 与 NN 的结合。</p>
<p><strong>模型结构：</strong></p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271357122.jpeg" />   
    </p>
<p>ONN 沿袭了 Embedding+MLP 结构。在 Embedding 层采用 Operation-aware Embedding，可以看到对于一个 feature，会得到多个 embedding 结果；在图中以红色虚线为分割，第一列的 embedding 是 feature 本身的 embedding 信息，从第二列开始往后是当前特征与第 n 个特征交叉所使用的 embedding。</p>
<p>在 Embedding features 层中，我们可以看到包含了两部分：</p>
<ul>
<li>左侧部分为每个特征本身的 embedding 信息，其代表了一阶特征信息</li>
<li>右侧部分是与 FFM 相同的二阶交叉特征部分</li>
</ul>
<p>这两部分 concat 之后接入 MLP 得到最后的预测结果。</p>
<p><strong>优势：</strong></p>
<ul>
<li>引入 Operation-aware，进一步增加了模型的表达能力</li>
<li>同时包含了特征一阶信息与高阶交叉信息</li>
</ul>
<p><strong>不足：</strong></p>
<ul>
<li>模型复杂度相对较高，每个 feature 对应多个 embedding 结果</li>
</ul>
<h2 id="五-双路并行的模型组合">五。 双路并行的模型组合</h2>
<p>这一部分将介绍双路并行的模型结构，之所以称为双路并行，是因为在这一部分的模型中，以 Wide&amp;Deep 和 DeepFM 为代表的模型架构都是采用了双路的结构。例如 Wide&amp;Deep 的左路为 Embedding+MLP，右路为 Cross Feature LR；DeepFM 的左路为 FM，右路为 Embedding+MLP。这类模型通过使用不同的模型进行联合训练，不同子模型之间互相弥补，增加整个模型信息表达和学习的多样性。</p>
<h3 id="1wdlwide-and-deep-learning-2016--memorization-与-generalization-的信息互补">（1）WDL：Wide and Deep Learning, 2016 —— Memorization 与 Generalization 的信息互补</h3>
<p>Wide And Deep 是 2016 年 Google 提出的用于 Google Play app 推荐业务的一种算法。其核心思想是通过结合 Wide 线性模型的记忆性（memorization）和 Deep 深度模型的泛化性（generalization）来对用户行为信息进行学习建模。</p>
<p><strong>模型结构：</strong></p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271357235.jpeg" />   
    </p>
<p><strong>优势：</strong></p>
<ul>
<li>Wide 层与 Deep 层互补互利，Deep 层弥补 Memorization 层泛化性不足的问题</li>
<li>wide 和 deep 的 joint training 可以减小 wide 部分的 model size（即只需要少数的交叉特征）</li>
<li>可以同时学习低阶特征交叉（wide 部分）和高阶特征交叉（deep 部分）</li>
</ul>
<h3 id="不足-1">不足：</h3>
<ul>
<li>仍需要手动设计交叉特征</li>
</ul>
<h3 id="2deepfmdeep-factorization-machines-2017--fm-基础上引入-nn-隐式高阶交叉信息"><strong>（2）DeepFM：Deep Factorization Machines, 2017 —— FM 基础上引入 NN 隐式高阶交叉信息</strong></h3>
<p>我们知道 FM 只能够去显式地捕捉二阶交叉信息，而对于高阶的特征组合却无能为力。DeepFM 就是在 FM 模型的基础上，增加 DNN 部分，进而提高模型对于高阶组合特征的信息提取。DeepFM 能够做到端到端的、自动的进行高阶特征组合，并且不需要人工干预。</p>
<p><strong>模型结构：</strong></p>
<p>DeepFM 包含了 FM 和 NN 两部分，这两部分共享了 Embedding 层：</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271357949.jpeg" />   
    </p>
<p>左侧 FM 部分就是 2-way 的 FM：包含了线性部分和二阶交叉部分右侧 NN 部分与 FM 共享 Embedding，将所有特征的 embedding 进行 concat 之后作为 NN 部分的输入，最终通过 NN 得到。</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271357875.svg&#43;xml" />   
    </p>
<p><strong>优势：</strong></p>
<ul>
<li>模型具备同时学习低阶与高阶特征的能力</li>
<li>共享 embedding 层，共享了特征的信息表达</li>
</ul>
<p><strong>不足：</strong></p>
<ul>
<li>DNN 部分对于高阶特征的学习仍然是隐式的</li>
</ul>
<hr>
<h2 id="六-复杂的显式特征交叉网络">六。 复杂的显式特征交叉网络</h2>
<p>无论是以 FNN、PNN、NFM、ONN 为代表的 Embedding+MLP，还是以 Wide&amp;Deep 和 DeepFM 为代表的双路模型，基本都是通过 DNN 来学习高阶特征交叉信息。但 DNN 本身对于特征交叉是隐式的（Implicit）、bit-wise 的，因此在这一阶段，以 DCN、xDeepFM、AutoInt 为代表的模型均把思路放在如何以 Explicit 的方式学习有限阶（bounded-degree）的特征交叉信息上。</p>
<blockquote>
<p>Bit-wise：even the elements within the same field embedding vector will influence each other.</p>
</blockquote>
<h3 id="1deepcrossdeep-and-cross-network-2017--显式交叉网络-cross-net-的诞生">（1）Deep&amp;Cross：Deep and Cross Network, 2017 —— 显式交叉网络 Cross Net 的诞生</h3>
<p>Deep&amp;Cross 其实也属于双路并行的模型结构，只不过提出了一种新的模型叫做 Cross Net 来替代 DeepFM 中的 FM 部分。DNN 本身虽然具备高阶交叉特征的学习能力，但其对于特征交叉的学习是隐式的、高度非线性的一种方式，因此作者提出了 Cross Net，它可以显式地进行特征的高阶交叉，CrossNet 相比于 DNN 的优势主要在于：</p>
<ul>
<li>可以显式地（Explicitly）学习有限阶（bounded-degree）的特征交叉</li>
<li>计算时间复杂度相比于 DNN 更加低</li>
</ul>
<p><strong>模型结构：</strong></p>
<p>DCN 模型包含了两部分，左边一路是通过 CrossNet 来显式地学习有限阶特征交叉，右边一路是通过 DNN 来隐式学习交叉特征，进一步提高模型的多样性和表达能力。</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271357350.jpeg" />   
    </p>
<p>CrossNet 的主要思想是显式地计算内积来进行层与层之间的信息交叉；另外，CrossNet 在设计上还借鉴了残差网络的思想，使得每一层的输出结果能够包含原始的输入信息。</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271357276.jpeg" />   
    </p>
<p>对于 CrossNet 中的某一层，其计算方法如上图所示。分为三部分：</p>
<ul>
<li>Feature Crossing：对 input embeddings 与上一层的输出进行交叉</li>
<li>Bias：偏置项</li>
<li>Input：上一层的输出（也是本层的输入）</li>
</ul>
<p>公式可以表达为：</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271358956.svg&#43;xml" />   
    </p>
<p>其中

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271358391.svg&#43;xml" />   
    
，通过上式得到

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271358548.svg&#43;xml" />   
    
，我们可以发现 mapping function

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271358844.svg&#43;xml" />   
    
正好在拟合两层网络之间的残差。对于 CrossNet 中的第

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271358609.svg&#43;xml" />   
    
层，其能够捕捉到的特征交叉的最高阶为

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271358865.svg&#43;xml" />   
    
。</p>
<p>CrossNet 本身在计算消耗上也不大，假设 CrossNet 共有

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271358767.svg&#43;xml" />   
    
层，输入的 input vector 是一个

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271358052.svg&#43;xml" />   
    
维向量，那么对于每一层来说有

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271358347.svg&#43;xml" />   
    
两个参数，即

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271358707.svg&#43;xml" />   
    
个参数，总共

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271359027.svg&#43;xml" />   
    
层，共有

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271359252.svg&#43;xml" />   
    
个参数，参数规模与输入的维度

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271359469.svg&#43;xml" />   
    
呈线性相关。</p>
<p><strong>优势：</strong></p>
<ul>
<li>具备显式高阶特征交叉的能力</li>
<li>结合 ResNet 的思想，可以将原始信息在 CrossNet 中进行传递</li>
</ul>
<p><strong>不足：</strong></p>
<ul>
<li>CrossNet 在进行交叉时是 bit-wise 方式</li>
<li>CrossNet 最终的输出有一定的局限性，CrossNet 的每一层输出都是输入向量

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271359775.svg&#43;xml" />   
    
的标量倍，这种形式在一定程度上限制了模型的表达能力</li>
</ul>
<blockquote>
<p>证明：</p>
<p>我们令 CrossNet 的输入为

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271359013.svg&#43;xml" />   
    
，忽略每一层中的 bias 项，对于第一次 cross，有：</p>
</blockquote>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271359267.svg&#43;xml" />   
    
，其中

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271359677.svg&#43;xml" />   
    
；</p>
<blockquote>
<p>对于第二次 cross，有：</p>
</blockquote>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271400860.svg&#43;xml" />   
    
，其中

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271400245.svg&#43;xml" />   
    </p>
<blockquote>
<p>基于上式进行推广可以得到

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271400833.svg&#43;xml" />   
    
，即证得 CrossNet 的输出是输入

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271400711.svg&#43;xml" />   
    
的标量倍。</p>
<p>这里要注意的是，

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271400362.svg&#43;xml" />   
    
与

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271400926.svg&#43;xml" />   
    
并不是线性关系，这是因为

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271400549.svg&#43;xml" />   
    
也是关于

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271401148.svg&#43;xml" />   
    
的函数。</p>
</blockquote>
<h3 id="2xdeepfmextreme-deep-factorization-machine-2018--compressed-interaction-network-的诞生">**（2）xDeepFM：**eXtreme Deep Factorization Machine, 2018 —— <strong>Compressed Interaction Network 的诞生</strong></h3>
<p>xDeepFM 全称为 eXtreme Deep Factorization Machine，可以看出其是在 DeepFM 基础上进行了改进。xDeepFM 的贡献主要在于提出了压缩交互网络（Compressed Interaction Network），与 DCN 相同的是，都提出了要 cross feature explicitly；但不同的是，DCN 中的特征交叉是 element-wise 的，而 CIN 中的特征交叉是 vector-wise 的。</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271401598.jpeg" />   
    </p>
<p><strong>模型结构：</strong></p>
<p>xDeepFM 模型结构如下，整个模型分为三个部分：</p>
<ul>
<li>Linear Part：捕捉线性特征</li>
<li>CIN Part：压缩交互网络，显式地、vector-wise 地学习高阶交叉特征</li>
<li>DNN Part：隐式地、bit-wise 地学习高阶交叉特征</li>
</ul>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271401456.jpeg" />   
    </p>
<p>CIN 网络的设计主要分为两步：交互（interaction）与压缩（compression）。</p>
<p>在交互部分，如下图（a）所示，将第

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271401492.svg&#43;xml" />   
    
层的 feature map 与

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271401337.svg&#43;xml" />   
    
（输入层，这里将输入层表示为一个

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271401814.svg&#43;xml" />   
    
的 tensor，其中 m 为特征个数，D 为 embedding 的 size）。在 D 的每一个维度上，进行外积计算，得到

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271401954.svg&#43;xml" />   
    
。</p>
<p>在压缩部分，借鉴了 CNN 卷积 +Pooling 的思想，先通过

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271401289.svg&#43;xml" />   
    
个 filter 将三维的

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271401582.svg&#43;xml" />   
    
（可看做一张图片）进行压缩计算，得到

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271401859.svg&#43;xml" />   
    
。紧接着在 D 维上进行 sum pooling 操作，得到最后输出向量（如 c 图中的黄色小圆圈）。</p>
<p>经过多个串行的压缩与交互步骤，可以得到多个输出向量，最终将这些向量 concat 起来，作为 CIN 的输出结果。</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271402258.jpeg" />   
    </p>
<p>可以看出 CIN 在计算上相对比较复杂，但是由于 CNN 参数共享机制以及 sum pooling 层的存在，CIN 部分的参数规模与特征的 Embedding size 大小

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271402236.svg&#43;xml" />   
    
是无关的。假设输入 field 有

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271402502.svg&#43;xml" />   
    
个，共有

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271402024.svg&#43;xml" />   
    
层，每层有

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271402101.svg&#43;xml" />   
    
个 feature map，那么 CIN 部分的参数规模为

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271402528.svg&#43;xml" />   
    
。</p>
<p>但是在时间复杂度上，CIN 存在很大劣势，CIN 的时间复杂度为

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271402321.svg&#43;xml" />   
    
。</p>
<p><strong>优势：</strong></p>
<ul>
<li>xDeepFM 可以同时学习到显式的高阶特征交叉（CIN）与隐式的高阶特征交叉（DNN）</li>
<li>在交叉特征的学习上，CIN 采用了 vector-wise 的交叉（而不是 DCN 中的 bit-wise 交叉）</li>
</ul>
<p><strong>不足：</strong></p>
<ul>
<li>CIN 在实际计算中时间复杂度过高</li>
<li>CIN 的 sum-pooling 操作会损失一定的信息</li>
</ul>
<h3 id="3autointautomatic-feature-interaction-learning-2019--跨领域-nlp-技术的引入multi-head-self-attention-提升模型表达">（3）AutoInt：Automatic Feature Interaction Learning, 2019 —— 跨领域 NLP 技术的引入：Multi-head Self-attention 提升模型表达</h3>
<p>AutoInt 是 2019 年发表的比较新的论文，它的思路和 DCN 以及 xDeepFM 相似，都是提出了能够显式学习高阶特征交叉的网络。除此之外，AutoInt 算法借鉴了 NLP 模型中 Transformer 的 Multi-head self-attention 机制，给模型的交叉特征引入了可解释性，可以让模型知道哪些特征交叉的重要性更大。</p>
<p>AutoInt 的 Attention 机制采用了 NLP 中标准的 Q,K,V 形式，即给定 Query 词和候选的 Key 词，计算相关性

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271402819.svg&#43;xml" />   
    
，再用

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271402146.svg&#43;xml" />   
    
对 Value 进行加权得到结果。</p>
<p><strong>模型结构：</strong></p>
<p>相比于 DCN 和 xDeepFM 采用交叉网络 +DNN 的双路结构，AutoInt 直接采用了单路的模型结构，将原始特征 Embedding 之后，直接采用多层 Interacting Layer 进行学习（作者在论文的实验部分也列出了 AutoInt+DNN 的双路模型结构：AutoInt+）。</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271402062.jpeg" />   
    </p>
<p>AutoInt 中的 Interacting Layer 包含了两部分：Multi-head Self-Attention 和 ResNet 部分。</p>
<p>在 self-attention 中，采用的是 Q,K,V 形式，具体来说：我们只考虑 1 个 head self-attention 的情况，假设我们共有

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271403158.svg&#43;xml" />   
    
个特征，对于输入的第

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271403416.svg&#43;xml" />   
    
个 feature embedding 来说，AutoInt 认为它与

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271403157.svg&#43;xml" />   
    
个特征交叉后的特征拥有不同的权重，对于我们第

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271403468.svg&#43;xml" />   
    
个特征，它与第

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271403980.svg&#43;xml" />   
    
个特征交叉的权重为：</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271403054.svg&#43;xml" />   
    </p>
<p>其中

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271403179.svg&#43;xml" />   
    
，函数

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271403754.svg&#43;xml" />   
     是衡量两个向量距离的函数，在 AutoInt 中作者采用了简单高效的向量内积来计算距离。得到权重信息后，我们对 M 个特征的 Value 进行加权：

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271404967.svg&#43;xml" />   
     ，得到向量 m 与其余特征的加权二阶交叉信息。</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271404250.jpeg" />   
    </p>
<p>进一步地，作者使用了多个 self-attention（multi-head self-attention）来计算不同 subspaces 中的特征交叉，其实就是进一步增加了模型的表达能力。采用 h 个 multi-head 之后，我们会得到 h 个

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271404253.svg&#43;xml" />   
     ，将这 h 个

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271404857.svg&#43;xml" />   
     concat 起来，得到

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271404585.svg&#43;xml" />   
     。</p>
<p>为了保留上一步学到的交叉信息，AutoInt 和 CrossNet 一样，都使用了 ResNet 的思想：</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271404330.svg&#43;xml" />   
    </p>
<p>使用 ResNet 可以使得之前学习到的信息也被更新到新的层中，例如第一层原始的 embedding 也可以被融入到最终的输出中。</p>
<p>剩余的特征也以同样的方式进行 multi-head attention 计算，得到

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271404596.svg&#43;xml" />   
     ，将这 M 个向量 concat 之后连接输出层得到最终的预估值。</p>
<p><strong>优势：</strong></p>
<ul>
<li>AutoInt 可以显示地、以 vector-wise 的方式地学习有限阶（bounded-degree）特征交叉信息</li>
<li>可以以 low interacting layer 学习到 higher-order feature interaction</li>
</ul>
<blockquote>
<p>原文这里给出了一个例子，两层 Interacting Layer 就可以学习到 4 阶特征交叉。定义交叉函数为

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271404243.svg&#43;xml" />   
    
， 假如我们有 4 个特征

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271404547.svg&#43;xml" />   
     ，第一层 Interacting Layer 之后，我们可以得到

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271405659.svg&#43;xml" />   
     等二阶交叉信息，即两两特征的二阶交叉；将二阶交叉送入下一层 Interacting Layer 之后，由于输入第一层网络融入了二阶交叉信息，那么在本层中就可以得到四阶交叉，如

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271405071.svg&#43;xml" />   
     就可以通过

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271405562.svg&#43;xml" />   
     得到。</p>
</blockquote>
<ul>
<li>Interacting Layer 的参数规模与输入特征个数

        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271405245.svg&#43;xml" />   
     无关。</li>
</ul>
<hr>
<h2 id="七-ctr-预估模型总结与比较">七。 CTR 预估模型总结与比较</h2>
<p>至此我们基本介绍完成了大多数常见的 CTR 预估模型，当然还有 MLR、DIN、DIEN 等其它的模型，由于篇幅限制暂时没有进行介绍。纵观整个 CTR 预估模型的发展过程，我们可以总结出一定的规律，这一部分主要是对上述模型的关系图谱以及特征进行总结。</p>
<h3 id="1ctr-预估模型关系图谱">（1）CTR 预估模型关系图谱</h3>
<p>现在我们再回头来看开篇的这张关系图：</p>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271405195.jpeg" />   
    </p>
<p>从上往下，代表了整个 CTR 预估的发展趋势：</p>
<ul>
<li><strong>LR 的主要限制在于需要大量手动特征工程来间接提高模型表达，此时出现了两个发展方向：</strong>
<ul>
<li>以 FM 为代表的端到端的隐向量学习方式，通过 embedding 来学习二阶交叉特征</li>
<li>以 GBDT+LR 为代表的两阶段模型，第一阶段利用树模型优势自动化提取高阶特征交叉，第二阶段交由 LR 进行最终的学习</li>
</ul>
</li>
<li><strong>以 FM 为结点，出现了两个方向：</strong></li>
<li>以 FFM 与 AFM 为代表的浅层模型改进。这两个模型本质上还是学习低阶交叉特征，只是在 FM 基础上为不同的交叉特征赋予的不同重要度</li>
<li>深度学习时代到来，依附于 DNN 高阶交叉特征能力的 Embedding+MLP 结构开始流行</li>
<li><strong>以 Embedding+MLP 为结点：</strong></li>
<li>Embedding 层的改造 +DNN 进行高阶隐式学习，出现了以 PNN、NFM 为代表的 product layer、bi-interaction layer 等浅层改进，这一类模型都是对 embedding 层进行改造来提高模型在浅层表达，减轻后续 DNN 的学习负担</li>
<li>以 W&amp;D 和 DeepFM 为代表的双路模型结构，将各个子模块算法的优势进行互补，例如 DeepFM 结合了 FM 的低阶交叉信息和 DNN 的高阶交叉信息学习能力</li>
<li>显式高阶特征交叉网络的提出，这一阶段以更复杂的网络方式来进行显式交叉特征的学习，例如 DCN 的 CrossNet、xDeepFM 的 CIN、AutoInt 的 Multi-head Self-attention 结构</li>
</ul>
<p>从整个宏观趋势来看，每一阶段新算法的提出都是在不断去提升模型的表达能力，从二阶交叉，到高阶隐式交叉，再到如今的高阶显示交叉，模型对于原始信息的学习方式越来越复杂的同时，也越来越准确。</p>
<p>图中右侧红色字体提取了部分模型之间的共性：</p>
<ul>
<li>**Hand-crafted features：**LR 与 W&amp;D 都需要进行手动的特征工程</li>
<li>**Non-end-to-end：**GBDT+LR 通过树模型提取特征 +LR 建模的两阶段，FNN 则是 FM 预训练 embedding+DNN 建模的两阶段方式，这两者都是非端到端的模型</li>
<li>**Multi-embeddings：**这里是指对于同一个特征，使用多个 embedding 来提升信息表达。包括 FFM 的 Field-aware，ONN 的 Operation-aware</li>
<li>**Attention：**Attention 机制为 CTR 预估中的交叉特征赋予了不同的重要性，也增加了一定的可解释性。AFM 中采用单个隐藏层的神经网络构建 attention 层，AutoInt 在 Interacting Layer 中采用 NLP 中 QKV 形式学习 multi-head self-attention</li>
<li>**Explicitly Interactions：**DNN 本身学习的是隐式特征交叉，DCN、xDeepFM、AutoInt 则都提出了显式特征交叉的网络结构</li>
<li>**ResNet：**ResNet 的引入是为了保留历史的学习到的信息，CrossNet 与 AutoInt 中都采用了 ResNet 结构</li>
</ul>
<h3 id="2ctr-预估模型特性对比">（2）CTR 预估模型特性对比</h3>
<p>这里对比主要包含了一下几个方面：</p>
<ul>
<li>No Pretraining：是否需要预训练</li>
<li>Automatic Feature Engineering：是否自动进行特征组合与特征工程</li>
<li>End-To-End：是否是端到端的模型</li>
<li>Low-Order Features：是否包含低阶特征信息</li>
<li>High-Order Features：是否包含高阶特征信息</li>
<li>Explicitly High-Order Crossing：是否包含显式特征交叉</li>
</ul>
<p>
        <img class="mx-auto" alt="" src="https://cdn.jsdelivr.net/gh/zshipu/imagesv2@main/2023/202312271405879.jpeg" />   
    </p>
<h2 id="结语">结语</h2>
<p>至此我们对于常见的 CTR 预估模型的演进过程与关系就讲解完毕，纵观整个过程，CTR 预估模型从开始的 LR，到利用树模型自动化组合特征，再发展到端到端的 Embedding+MLP 结构，再到如今越来越复杂的显式交叉网络等，每一次发展都是在不断提升模型对于用户行为的表达与学习能力。CTR 预估不仅是一个数学优化问题，更是一个工程问题，因此如何能够以较低的计算成本，高效地提高模型表达能力将是未来需要努力的方向。</p>
<p><strong>参考文献：</strong></p>
<p>[1] Rendle, Steffen. &ldquo;Factorization Machines.&rdquo; 2011.</p>
<p>[2] Mcartney, D . &ldquo;Proceedings of the Eighth International Workshop on Data Mining for Online Advertising.&rdquo; <em>Eighth International Workshop on Data Mining for Online Advertising</em> ACM, 2014.</p>
<p>[3] Zhang, Weinan , T. Du , and J. Wang . &ldquo;Deep Learning over Multi-field Categorical Data: A Case Study on User Response Prediction.&rdquo; (2016).</p>
<p>[4] Product-base Neural Networks for user responses</p>
<p>[5] Xiangnan He, and Tat-Seng Chua. &ldquo;Neural Factorization Machines for Sparse Predictive Analytics.&rdquo; <em>the 40th International ACM SIGIR Conference</em> ACM, 2017.</p>
<p>[6] Yang, Yi.et. &ldquo;Operation-aware Neural Networks for User Response Prediction.&rdquo;.</p>
<p>[7] Juan, Yuchin, Lefortier, Damien, and Chapelle, Olivier. &ldquo;Field-aware Factorization Machines in a Real-world Online Advertising System.&rdquo;.</p>
<p>[8] Xiao, Jun, Ye, Hao, He, Xiangnan, Zhang, Hanwang, Wu, Fei, &amp; Chua, Tat-Seng. . Attentional factorization machines: learning the weight of feature interactions via attention networks.</p>
<p>[9] Cheng, Heng Tze , et al. &ldquo;Wide &amp; Deep Learning for Recommender Systems.&rdquo; (2016).</p>
<p>[10] Guo, Huifeng, Tang, Ruiming, Ye, Yunming, Li, Zhenguo, &amp; He, Xiuqiang. . Deepfm: a factorization-machine based neural network for ctr prediction.</p>
<p>[11] Wang, Ruoxi, Fu, Bin, Fu, Gang, &amp; Wang, Mingliang. . Deep &amp; cross network for ad click predictions.</p>
<p>[12] Lian, Jianxun, Zhou, Xiaohuan, Zhang, Fuzheng, Chen, Zhongxia, Xie, Xing, &amp; Sun, Guangzhong. . Xdeepfm: combining explicit and implicit feature interactions for recommender systems.</p>
<p>[13] Song, Weiping, Shi, Chence, Xiao, Zhiping, Duan, Zhijian, Xu, Yewen, &amp; Zhang, Mi</p>

        </div>

        
<div class="post-archive">
    <ul class="post-copyright">
        <li><strong>原文作者：</strong><a rel="author" href="https://geek.zshipu.com/">知识铺</a></li>
        <li style="word-break:break-all"><strong>原文链接：</strong><a href="https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E4%B8%87%E5%AD%97%E9%95%BF%E6%96%87%E6%A2%B3%E7%90%86%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95%E8%BF%87%E7%A8%8B%E4%B8%8E%E5%85%B3%E7%B3%BB%E5%9B%BE%E8%B0%B1/">https://geek.zshipu.com/post/%E4%BA%92%E8%81%94%E7%BD%91/%E4%B8%87%E5%AD%97%E9%95%BF%E6%96%87%E6%A2%B3%E7%90%86%E9%A2%84%E4%BC%B0%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95%E8%BF%87%E7%A8%8B%E4%B8%8E%E5%85%B3%E7%B3%BB%E5%9B%BE%E8%B0%B1/</a></li>
        <li><strong>版权声明：</strong>本作品采用<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议</a>进行许可，非商业转载请注明出处（作者，原文链接），商业转载请联系作者获得授权。</li>
        <li><strong>免责声明：</strong>本页面内容均来源于站内编辑发布，部分信息来源互联网，并不意味着本站赞同其观点或者证实其内容的真实性，如涉及版权等问题，请立即联系客服进行更改或删除，保证您的合法权益。转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。也可以邮件至 sblig@126.com</li>
    </ul>
</div>
<br/>



        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/post/%E4%BA%92%E8%81%94%E7%BD%91/%E7%94%A8%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%80%8E%E6%A0%B7%E9%89%B4%E5%88%AB%E4%B8%8D%E5%8F%AF%E6%8F%8F%E8%BF%B0%E7%9A%84%E7%BD%91%E7%AB%99/">用机器学习怎样鉴别不可描述的网站</a></li>
        
        <li><a href="/post/%E4%BA%92%E8%81%94%E7%BD%91/%E4%B8%8D%E4%BB%85%E4%BB%85%E7%94%A8%E9%80%9A%E8%BF%87%E4%BA%BA%E5%B7%A5%E8%AF%84%E4%BC%B0%E5%BE%97%E5%88%B0%E6%9B%B4%E5%A5%BD%E7%9A%84%E6%8E%A8%E8%8D%90/">不仅仅用通过人工评估得到更好的推荐</a></li>
        
        <li><a href="/post/%E4%BA%92%E8%81%94%E7%BD%91/%E7%9A%84%E5%B5%8C%E5%85%A5%E5%B1%82%E6%98%AF%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%9A%84%E7%9C%8B%E5%AE%8C%E4%BD%A0%E5%B0%B1%E6%98%8E%E7%99%BD%E4%BA%86/">的嵌入层是如何实现的看完你就明白了</a></li>
        
        <li><a href="/post/%E4%BA%92%E8%81%94%E7%BD%91/%E8%92%8B%E8%83%BD%E5%AD%A6%E7%BD%91%E6%98%93%E4%BA%91%E9%9F%B3%E4%B9%90%E5%B9%BF%E5%91%8A%E7%AE%97%E6%B3%95%E5%AE%9E%E8%B7%B5/">蒋能学网易云音乐广告算法实践</a></li>
        
        <li><a href="/post/%E4%BA%92%E8%81%94%E7%BD%91/%E4%BC%98%E9%85%B7%E6%8F%90%E5%87%BA%E5%9F%BA%E4%BA%8E%E5%9B%BE%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E%E7%9A%84%E7%AE%97%E6%B3%95%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E6%A6%82%E8%A7%88/">优酷提出基于图执行引擎的算法服务框架系统架构概览</a></li>
        
    </ul>
</div>


        <div class="post-meta meta-tags">
            
            <ul class="clearfix">
                
                <li><a href='/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD'>人工智能</a></li>
                
                <li><a href='/tags/%E7%AE%97%E6%B3%95'>算法</a></li>
                
                <li><a href='/tags/CTR%E9%A2%84%E4%BC%B0'>CTR预估</a></li>
                
            </ul>
            
        </div>
    </article>
    
    

    
    
    <div class="post bg-white">
      <script src="https://utteranc.es/client.js"
            repo= "zshipu/zshipu-geek"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
      </script>
    </div>
    
</div>

                    <footer id="footer">
    <div>
        &copy; 2024 <a href="https://geek.zshipu.com/">知识铺的博客 By 知识铺</a>
        
        | <a rel="nofollow" target="_blank" href="https://beian.miit.gov.cn/">浙 ICP 备19032823号-1</a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>


    
    <script type="text/javascript">
        window.MathJax = {
            tex2jax: {
                inlineMath: [['$', '$']],
                processEscapes: true
                }
            };
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://geek.zshipu.com/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://geek.zshipu.com/">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://geek.zshipu.com/post/picggo/PicGo%E5%8F%91%E5%B8%832.3.1/" title="PicGo发布2.3.1">PicGo发布2.3.1</a>
    </li>
    
    <li>
        <a href="https://geek.zshipu.com/post/ux/%E6%89%8B%E6%9C%BA%E5%9E%8B%E5%8F%B7/" title="UX 设计：手机型号和尺寸">UX 设计：手机型号和尺寸</a>
    </li>
    
    <li>
        <a href="https://geek.zshipu.com/post/java/JavaScript-%E5%8E%8B%E7%BC%A9-Java-%E8%A7%A3%E5%8E%8B%E7%BC%A9/" title="JavaScript 中压缩数据，然后在 Java 中解压缩">JavaScript 中压缩数据，然后在 Java 中解压缩</a>
    </li>
    
    <li>
        <a href="https://geek.zshipu.com/post/java/%E6%8F%AD%E7%A7%98-Java-Record%E6%9B%B4%E5%A5%BD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/" title="揭秘 Java Record：更好的数据处理">揭秘 Java Record：更好的数据处理</a>
    </li>
    
    <li>
        <a href="https://geek.zshipu.com/post/bi/flink/2077-%E7%AC%AC42%E8%AE%B2Flink-%E9%9D%A2%E8%AF%95-%E6%96%B9%E6%A1%88%E8%AE%BE%E8%AE%A1%E7%AF%87/" title="Flink系列-第42讲：Flink 面试-方案设计篇">Flink系列-第42讲：Flink 面试-方案设计篇</a>
    </li>
    
    <li>
        <a href="https://geek.zshipu.com/post/bi/flink/2076-%E7%AC%AC41%E8%AE%B2Flink-%E9%9D%A2%E8%AF%95-%E6%BA%90%E7%A0%81%E7%AF%87/" title="Flink系列-第41讲：Flink 面试-源码篇">Flink系列-第41讲：Flink 面试-源码篇</a>
    </li>
    
    <li>
        <a href="https://geek.zshipu.com/post/bi/flink/2075-%E7%AC%AC40%E8%AE%B2Flink-%E9%9D%A2%E8%AF%95-%E8%BF%9B%E9%98%B6%E7%AF%87/" title="Flink系列-第40讲：Flink 面试-进阶篇">Flink系列-第40讲：Flink 面试-进阶篇</a>
    </li>
    
    <li>
        <a href="https://geek.zshipu.com/post/bi/flink/2074-%E7%AC%AC39%E8%AE%B2Flink-%E9%9D%A2%E8%AF%95-%E5%9F%BA%E7%A1%80%E7%AF%87/" title="Flink系列-第39讲：Flink 面试-基础篇">Flink系列-第39讲：Flink 面试-基础篇</a>
    </li>
    
    <li>
        <a href="https://geek.zshipu.com/post/bi/flink/2073-%E7%AC%AC38%E8%AE%B2Flink-%E8%B0%83%E7%94%A8-CEP-%E5%AE%9E%E7%8E%B0%E6%8A%A5%E8%AD%A6%E5%8A%9F%E8%83%BD/" title="Flink系列- 第38讲：Flink 调用 CEP 实现报警功能">Flink系列- 第38讲：Flink 调用 CEP 实现报警功能</a>
    </li>
    
    <li>
        <a href="https://geek.zshipu.com/post/bi/flink/2072-%E7%AC%AC37%E8%AE%B2%E8%87%AA%E5%AE%9A%E4%B9%89-Pattern-%E5%92%8C%E6%8A%A5%E8%AD%A6%E8%A7%84%E5%88%99/" title="Flink系列- 第37讲：自定义 Pattern 和报警规则">Flink系列- 第37讲：自定义 Pattern 和报警规则</a>
    </li>
    
</ul>
    </section>

    
<section class="widget">
    <h3 class="widget-title" style="color:red">福利派送</h3>
    <ul class="widget-list">
        
        <li>
            <a href="https://promotion.aliyun.com/ntms/yunparter/invite.html?source=5176.11533457&amp;userCode=tzm8r4hc" title="【2019双12】ALL IN CLoud 低至1折" target="_blank" style="color:red">
                
                    <img src="https://img.alicdn.com/tfs/TB1_rYHo7P2gK0jSZPxXXacQpXa-690-388.jpg">
                
            </a>
        </li>
        
        <li>
            <a href="https://promotion.aliyun.com/ntms/yunparter/invite.html?source=5176.11533457&amp;userCode=tzm8r4hc" title="助力产业智慧升级，云服务器首年88元起，更有千元代金券礼包免费领！" target="_blank" style="color:red">
                
                    <img src="https://upload-dianshi-1255598498.file.myqcloud.com/345-7c71532bd4935fbdd9a67c1a71e577b1767b805c.200%E7%89%88%E6%9C%ACB.jpg">
                
            </a>
        </li>
        
        <li>
            <a href="https://promotion.aliyun.com/ntms/yunparter/invite.html?source=5176.11533457&amp;userCode=tzm8r4hc" title="【渠道专享低折扣】11月特惠 限时2折" target="_blank" style="color:red">
                
                    <img src="https://img.alicdn.com/tfs/TB1hblJl7Y2gK0jSZFgXXc5OFXa-750-400.jpg">
                
            </a>
        </li>
        
    </ul>
</section>


    <section class="widget">
        <h3 class="widget-title"><a href='/categories/'>分类</a></h3>
<ul class="widget-list">
    
    <li><a href="https://geek.zshipu.com/categories/flutter/">flutter (30)</a></li>
    
    <li><a href="https://geek.zshipu.com/categories/iOS/">iOS (7)</a></li>
    
    <li><a href="https://geek.zshipu.com/categories/unix/">unix (9)</a></li>
    
    <li><a href="https://geek.zshipu.com/categories/%E7%AE%97%E6%B3%95/">算法 (3)</a></li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href='/tags/'>标签</a></h3>
<div class="tagcloud">
    
    <a href="https://geek.zshipu.com/tags/360%E6%90%9C%E7%B4%A2/">360搜索</a>
    
    <a href="https://geek.zshipu.com/tags/58%E5%90%8C%E5%9F%8E/">58同城</a>
    
    <a href="https://geek.zshipu.com/tags/AB%E6%B5%8B%E8%AF%95/">AB测试</a>
    
    <a href="https://geek.zshipu.com/tags/AFM%E6%A8%A1%E5%9E%8B/">AFM模型</a>
    
    <a href="https://geek.zshipu.com/tags/AI/">AI</a>
    
    <a href="https://geek.zshipu.com/tags/AILab/">AILab</a>
    
    <a href="https://geek.zshipu.com/tags/AI%E5%B9%B3%E5%8F%B0/">AI平台</a>
    
    <a href="https://geek.zshipu.com/tags/AKF%E6%9E%B6%E6%9E%84/">AKF架构</a>
    
    <a href="https://geek.zshipu.com/tags/ANN/">ANN</a>
    
    <a href="https://geek.zshipu.com/tags/AOF/">AOF</a>
    
    <a href="https://geek.zshipu.com/tags/AQS/">AQS</a>
    
    <a href="https://geek.zshipu.com/tags/ASR/">ASR</a>
    
    <a href="https://geek.zshipu.com/tags/AUC/">AUC</a>
    
    <a href="https://geek.zshipu.com/tags/AdaBoost/">AdaBoost</a>
    
    <a href="https://geek.zshipu.com/tags/AdaDeltaW/">AdaDeltaW</a>
    
    <a href="https://geek.zshipu.com/tags/AdamW/">AdamW</a>
    
    <a href="https://geek.zshipu.com/tags/Airbnb/">Airbnb</a>
    
    <a href="https://geek.zshipu.com/tags/Alink/">Alink</a>
    
    <a href="https://geek.zshipu.com/tags/Announcement/">Announcement</a>
    
    <a href="https://geek.zshipu.com/tags/ApacheFlink/">ApacheFlink</a>
    
    <a href="https://geek.zshipu.com/tags/AresDB/">AresDB</a>
    
    <a href="https://geek.zshipu.com/tags/Augur/">Augur</a>
    
    <a href="https://geek.zshipu.com/tags/AutoML/">AutoML</a>
    
    <a href="https://geek.zshipu.com/tags/Automaton/">Automaton</a>
    
    <a href="https://geek.zshipu.com/tags/BERT/">BERT</a>
    
    <a href="https://geek.zshipu.com/tags/BI/">BI</a>
    
    <a href="https://geek.zshipu.com/tags/BI%E5%B9%B3%E5%8F%B0/">BI平台</a>
    
    <a href="https://geek.zshipu.com/tags/BPR/">BPR</a>
    
    <a href="https://geek.zshipu.com/tags/Bagging/">Bagging</a>
    
    <a href="https://geek.zshipu.com/tags/Bandits/">Bandits</a>
    
    <a href="https://geek.zshipu.com/tags/BigGAN/">BigGAN</a>
    
    <a href="https://geek.zshipu.com/tags/CNN/">CNN</a>
    
    <a href="https://geek.zshipu.com/tags/CRF/">CRF</a>
    
    <a href="https://geek.zshipu.com/tags/CTR/">CTR</a>
    
    <a href="https://geek.zshipu.com/tags/CTR%E6%A8%A1%E5%9E%8B/">CTR模型</a>
    
    <a href="https://geek.zshipu.com/tags/CTR%E9%A2%84%E4%BC%B0/">CTR预估</a>
    
    <a href="https://geek.zshipu.com/tags/CV/">CV</a>
    
    <a href="https://geek.zshipu.com/tags/CVPR/">CVPR</a>
    
    <a href="https://geek.zshipu.com/tags/ClickHouse/">ClickHouse</a>
    
    <a href="https://geek.zshipu.com/tags/Condition/">Condition</a>
    
    <a href="https://geek.zshipu.com/tags/DDD/">DDD</a>
    
    <a href="https://geek.zshipu.com/tags/DDD%E5%AE%9E%E6%88%98/">DDD实战</a>
    
    <a href="https://geek.zshipu.com/tags/DIN/">DIN</a>
    
    <a href="https://geek.zshipu.com/tags/DKN%E6%A8%A1%E5%9E%8B/">DKN模型</a>
    
    <a href="https://geek.zshipu.com/tags/DMP%E5%B9%B3%E5%8F%B0/">DMP平台</a>
    
    <a href="https://geek.zshipu.com/tags/DPP/">DPP</a>
    
    <a href="https://geek.zshipu.com/tags/DRN/">DRN</a>
    
    <a href="https://geek.zshipu.com/tags/DSP/">DSP</a>
    
    <a href="https://geek.zshipu.com/tags/DSSM/">DSSM</a>
    
    <a href="https://geek.zshipu.com/tags/DeepFFM/">DeepFFM</a>
    
    <a href="https://geek.zshipu.com/tags/DeepFM/">DeepFM</a>
    
    <a href="https://geek.zshipu.com/tags/DeepFM%E6%A8%A1%E5%9E%8B/">DeepFM模型</a>
    
    <a href="https://geek.zshipu.com/tags/DevOps/">DevOps</a>
    
    <a href="https://geek.zshipu.com/tags/DevOps/">DevOps</a>
    
    <a href="https://geek.zshipu.com/tags/Dgraph/">Dgraph</a>
    
    <a href="https://geek.zshipu.com/tags/Doris/">Doris</a>
    
    <a href="https://geek.zshipu.com/tags/Druid/">Druid</a>
    
    <a href="https://geek.zshipu.com/tags/EE%E9%97%AE%E9%A2%98/">EE问题</a>
    
    <a href="https://geek.zshipu.com/tags/ELK/">ELK</a>
    
    <a href="https://geek.zshipu.com/tags/ELMo/">ELMo</a>
    
    <a href="https://geek.zshipu.com/tags/ESSM/">ESSM</a>
    
    <a href="https://geek.zshipu.com/tags/ETL/">ETL</a>
    
    <a href="https://geek.zshipu.com/tags/Embedding/">Embedding</a>
    
    <a href="https://geek.zshipu.com/tags/Epoll/">Epoll</a>
    
    <a href="https://geek.zshipu.com/tags/FFM/">FFM</a>
    
    <a href="https://geek.zshipu.com/tags/FFM%E6%A8%A1%E5%9E%8B/">FFM模型</a>
    
    <a href="https://geek.zshipu.com/tags/FM/">FM</a>
    
    <a href="https://geek.zshipu.com/tags/FM%E6%A8%A1%E5%9E%8B/">FM模型</a>
    
    <a href="https://geek.zshipu.com/tags/FST/">FST</a>
    
    <a href="https://geek.zshipu.com/tags/FTRL/">FTRL</a>
    
    <a href="https://geek.zshipu.com/tags/Faraday/">Faraday</a>
    
    <a href="https://geek.zshipu.com/tags/Feed%E6%B5%81/">Feed流</a>
    
    <a href="https://geek.zshipu.com/tags/FixMatch/">FixMatch</a>
    
    <a href="https://geek.zshipu.com/tags/FixedBitSet/">FixedBitSet</a>
    
    <a href="https://geek.zshipu.com/tags/Flink/">Flink</a>
    
    <a href="https://geek.zshipu.com/tags/FreeWheel/">FreeWheel</a>
    
    <a href="https://geek.zshipu.com/tags/FullGC/">FullGC</a>
    
    <a href="https://geek.zshipu.com/tags/GAN/">GAN</a>
    
    <a href="https://geek.zshipu.com/tags/GBDT/">GBDT</a>
    
    <a href="https://geek.zshipu.com/tags/GBDT&#43;LR%E8%9E%8D%E5%90%88/">GBDT&#43;LR融合</a>
    
    <a href="https://geek.zshipu.com/tags/GBM/">GBM</a>
    
    <a href="https://geek.zshipu.com/tags/GC/">GC</a>
    
    <a href="https://geek.zshipu.com/tags/GNN/">GNN</a>
    
    <a href="https://geek.zshipu.com/tags/GRU4REC/">GRU4REC</a>
    
    <a href="https://geek.zshipu.com/tags/Git/">Git</a>
    
    <a href="https://geek.zshipu.com/tags/Google/">Google</a>
    
    <a href="https://geek.zshipu.com/tags/GraphScope/">GraphScope</a>
    
    <a href="https://geek.zshipu.com/tags/Ha3/">Ha3</a>
    
    <a href="https://geek.zshipu.com/tags/Hbase/">Hbase</a>
    
    <a href="https://geek.zshipu.com/tags/Hologres/">Hologres</a>
    
    <a href="https://geek.zshipu.com/tags/Hystrix/">Hystrix</a>
    
    <a href="https://geek.zshipu.com/tags/IM/">IM</a>
    
    <a href="https://geek.zshipu.com/tags/IRGAN/">IRGAN</a>
    
    <a href="https://geek.zshipu.com/tags/IT%E5%8D%9A%E5%A3%AB/">IT博士</a>
    
    <a href="https://geek.zshipu.com/tags/IT%E7%A7%BB%E6%B0%91/">IT移民</a>
    
    <a href="https://geek.zshipu.com/tags/Iceberg/">Iceberg</a>
    
    <a href="https://geek.zshipu.com/tags/ImageNet/">ImageNet</a>
    
    <a href="https://geek.zshipu.com/tags/Impala/">Impala</a>
    
    <a href="https://geek.zshipu.com/tags/InnoDB/">InnoDB</a>
    
    <a href="https://geek.zshipu.com/tags/IntBlockPool/">IntBlockPool</a>
    
    <a href="https://geek.zshipu.com/tags/js/">js</a>
    
    <a href="https://geek.zshipu.com/tags/JanusGraph/">JanusGraph</a>
    
    <a href="https://geek.zshipu.com/tags/java/">java</a>
    
    <a href="https://geek.zshipu.com/tags/JavaScript/">JavaScript</a>
    
    <a href="https://geek.zshipu.com/tags/KBQA/">KBQA</a>
    
    <a href="https://geek.zshipu.com/tags/KV%E5%AD%98%E5%82%A8/">KV存储</a>
    
    <a href="https://geek.zshipu.com/tags/Kubernetes/">Kubernetes</a>
    
    <a href="https://geek.zshipu.com/tags/LDA/">LDA</a>
    
    <a href="https://geek.zshipu.com/tags/LSTM/">LSTM</a>
    
    <a href="https://geek.zshipu.com/tags/LSTM%E7%BD%91%E7%BB%9C/">LSTM网络</a>
    
    <a href="https://geek.zshipu.com/tags/LambdaMART/">LambdaMART</a>
    
    <a href="https://geek.zshipu.com/tags/Linux/">Linux</a>
    
    <a href="https://geek.zshipu.com/tags/LruCache/">LruCache</a>
    
    <a href="https://geek.zshipu.com/tags/Lucence/">Lucence</a>
    
    <a href="https://geek.zshipu.com/tags/MKR%E6%A8%A1%E5%9E%8B/">MKR模型</a>
    
    <a href="https://geek.zshipu.com/tags/MLflow/">MLflow</a>
    
    <a href="https://geek.zshipu.com/tags/MMoE/">MMoE</a>
    
    <a href="https://geek.zshipu.com/tags/MRR/">MRR</a>
    
    <a href="https://geek.zshipu.com/tags/Milvus/">Milvus</a>
    
    <a href="https://geek.zshipu.com/tags/MoE/">MoE</a>
    
    <a href="https://geek.zshipu.com/tags/Mock/">Mock</a>
    
    <a href="https://geek.zshipu.com/tags/Monorepo/">Monorepo</a>
    
    <a href="https://geek.zshipu.com/tags/mysql/">mysql</a>
    
    <a href="https://geek.zshipu.com/tags/NDCG/">NDCG</a>
    
    <a href="https://geek.zshipu.com/tags/NER/">NER</a>
    
    <a href="https://geek.zshipu.com/tags/NIO/">NIO</a>
    
    <a href="https://geek.zshipu.com/tags/NIPS/">NIPS</a>
    
    <a href="https://geek.zshipu.com/tags/NLP/">NLP</a>
    
    <a href="https://geek.zshipu.com/tags/Netty/">Netty</a>
    
    <a href="https://geek.zshipu.com/tags/nextjs/">nextjs</a>
    
    <a href="https://geek.zshipu.com/tags/nextjs/">nextjs</a>
    
    <a href="https://geek.zshipu.com/tags/OCR/">OCR</a>
    
    <a href="https://geek.zshipu.com/tags/OKR/">OKR</a>
    
    <a href="https://geek.zshipu.com/tags/OPPO/">OPPO</a>
    
    <a href="https://geek.zshipu.com/tags/PageRank/">PageRank</a>
    
    <a href="https://geek.zshipu.com/tags/Pinot/">Pinot</a>
    
    <a href="https://geek.zshipu.com/tags/Pulsar/">Pulsar</a>
    
    <a href="https://geek.zshipu.com/tags/Push%E7%B3%BB%E7%BB%9F/">Push系统</a>
    
    <a href="https://geek.zshipu.com/tags/QA/">Q&amp;A</a>
    
    <a href="https://geek.zshipu.com/tags/Que2Search/">Que2Search</a>
    
    <a href="https://geek.zshipu.com/tags/Query%E6%89%A9%E5%B1%95/">Query扩展</a>
    
    <a href="https://geek.zshipu.com/tags/Query%E7%90%86%E8%A7%A3/">Query理解</a>
    
    <a href="https://geek.zshipu.com/tags/R-Tree/">R-Tree</a>
    
    <a href="https://geek.zshipu.com/tags/ROC/">ROC</a>
    
    <a href="https://geek.zshipu.com/tags/RTree/">RTree</a>
    
    <a href="https://geek.zshipu.com/tags/reactjs/">reactjs</a>
    
    <a href="https://geek.zshipu.com/tags/RippleNet/">RippleNet</a>
    
    <a href="https://geek.zshipu.com/tags/RocketMQ/">RocketMQ</a>
    
    <a href="https://geek.zshipu.com/tags/SHAP/">SHAP</a>
    
    <a href="https://geek.zshipu.com/tags/SIGAI/">SIGAI</a>
    
    <a href="https://geek.zshipu.com/tags/SVM/">SVM</a>
    
    <a href="https://geek.zshipu.com/tags/Serverless/">Serverless</a>
    
    <a href="https://geek.zshipu.com/tags/SimCLR/">SimCLR</a>
    
    <a href="https://geek.zshipu.com/tags/Softmax/">Softmax</a>
    
    <a href="https://geek.zshipu.com/tags/Stage/">Stage</a>
    
    <a href="https://geek.zshipu.com/tags/TFServing/">TFServing</a>
    
    <a href="https://geek.zshipu.com/tags/TensorFlow/">TensorFlow</a>
    
    <a href="https://geek.zshipu.com/tags/Topk/">Topk</a>
    
    <a href="https://geek.zshipu.com/tags/Transformer/">Transformer</a>
    
    <a href="https://geek.zshipu.com/tags/TurboSearch/">TurboSearch</a>
    
    <a href="https://geek.zshipu.com/tags/Typora/">Typora</a>
    
    <a href="https://geek.zshipu.com/tags/UX/">UX</a>
    
    <a href="https://geek.zshipu.com/tags/WebRTC/">WebRTC</a>
    
    <a href="https://geek.zshipu.com/tags/WideDeep/">Wide&amp;Deep</a>
    
    <a href="https://geek.zshipu.com/tags/Word2vec/">Word2vec</a>
    
    <a href="https://geek.zshipu.com/tags/XDL/">XDL</a>
    
    <a href="https://geek.zshipu.com/tags/XDeepFM/">XDeepFM</a>
    
    <a href="https://geek.zshipu.com/tags/XGBoost/">XGBoost</a>
    
    <a href="https://geek.zshipu.com/tags/XLNet/">XLNet</a>
    
    <a href="https://geek.zshipu.com/tags/Yoo%E8%A7%86%E9%A2%91/">Yoo视频</a>
    
    <a href="https://geek.zshipu.com/tags/YoshuaBengio/">YoshuaBengio</a>
    
    <a href="https://geek.zshipu.com/tags/ZeroSearch/">ZeroSearch</a>
    
    <a href="https://geek.zshipu.com/tags/Zookeeper/">Zookeeper</a>
    
    <a href="https://geek.zshipu.com/tags/abtest/">abtest</a>
    
    <a href="https://geek.zshipu.com/tags/android/">android</a>
    
    <a href="https://geek.zshipu.com/tags/apache/">apache</a>
    
    <a href="https://geek.zshipu.com/tags/apollo/">apollo</a>
    
    <a href="https://geek.zshipu.com/tags/boosting/">boosting</a>
    
    <a href="https://geek.zshipu.com/tags/checkpoint/">checkpoint</a>
    
    <a href="https://geek.zshipu.com/tags/css/">css</a>
    
    <a href="https://geek.zshipu.com/tags/cto/">cto</a>
    
    <a href="https://geek.zshipu.com/tags/elasticsearch/">elasticsearch</a>
    
    <a href="https://geek.zshipu.com/tags/flutter/">flutter</a>
    
    <a href="https://geek.zshipu.com/tags/game/">game</a>
    
    <a href="https://geek.zshipu.com/tags/github/">github</a>
    
    <a href="https://geek.zshipu.com/tags/gitlab/">gitlab</a>
    
    <a href="https://geek.zshipu.com/tags/go/">go</a>
    
    <a href="https://geek.zshipu.com/tags/golang/">golang</a>
    
    <a href="https://geek.zshipu.com/tags/graphql/">graphql</a>
    
    <a href="https://geek.zshipu.com/tags/hadoop/">hadoop</a>
    
    <a href="https://geek.zshipu.com/tags/java/">java</a>
    
    <a href="https://geek.zshipu.com/tags/jdbc/">jdbc</a>
    
    <a href="https://geek.zshipu.com/tags/js/">js</a>
    
    <a href="https://geek.zshipu.com/tags/kafka/">kafka</a>
    
    <a href="https://geek.zshipu.com/tags/lab/">lab</a>
    
    <a href="https://geek.zshipu.com/tags/linUCB%E6%96%B9%E6%B3%95/">linUCB方法</a>
    
    <a href="https://geek.zshipu.com/tags/lucene/">lucene</a>
    
    <a href="https://geek.zshipu.com/tags/mybatis/">mybatis</a>
    
    <a href="https://geek.zshipu.com/tags/mysql/">mysql</a>
    
    <a href="https://geek.zshipu.com/tags/nexp/">nexp</a>
    
    <a href="https://geek.zshipu.com/tags/nextjs/">nextjs</a>
    
    <a href="https://geek.zshipu.com/tags/nifi/">nifi</a>
    
    <a href="https://geek.zshipu.com/tags/node2vec/">node2vec</a>
    
    <a href="https://geek.zshipu.com/tags/nodejs/">nodejs</a>
    
    <a href="https://geek.zshipu.com/tags/npm/">npm</a>
    
    <a href="https://geek.zshipu.com/tags/olap/">olap</a>
    
    <a href="https://geek.zshipu.com/tags/one-hot/">one-hot</a>
    
    <a href="https://geek.zshipu.com/tags/oss/">oss</a>
    
    <a href="https://geek.zshipu.com/tags/python/">python</a>
    
    <a href="https://geek.zshipu.com/tags/pytorch/">pytorch</a>
    
    <a href="https://geek.zshipu.com/tags/query%E7%BA%A0%E9%94%99/">query纠错</a>
    
    <a href="https://geek.zshipu.com/tags/react/">react</a>
    
    <a href="https://geek.zshipu.com/tags/reactjs/">reactjs</a>
    
    <a href="https://geek.zshipu.com/tags/reactor/">reactor</a>
    
    <a href="https://geek.zshipu.com/tags/redis/">redis</a>
    
    <a href="https://geek.zshipu.com/tags/region/">region</a>
    
    <a href="https://geek.zshipu.com/tags/rpc/">rpc</a>
    
    <a href="https://geek.zshipu.com/tags/scala/">scala</a>
    
    <a href="https://geek.zshipu.com/tags/select/">select</a>
    
    <a href="https://geek.zshipu.com/tags/sharding/">sharding</a>
    
    <a href="https://geek.zshipu.com/tags/skleam/">skleam</a>
    
    <a href="https://geek.zshipu.com/tags/solr/">solr</a>
    
    <a href="https://geek.zshipu.com/tags/spark/">spark</a>
    
    <a href="https://geek.zshipu.com/tags/sqllit/">sqllit</a>
    
    <a href="https://geek.zshipu.com/tags/storm/">storm</a>
    
    <a href="https://geek.zshipu.com/tags/storybook/">storybook</a>
    
    <a href="https://geek.zshipu.com/tags/tailwind/">tailwind</a>
    
    <a href="https://geek.zshipu.com/tags/trace/">trace</a>
    
    <a href="https://geek.zshipu.com/tags/vivo/">vivo</a>
    
    <a href="https://geek.zshipu.com/tags/vuejs/">vuejs</a>
    
    <a href="https://geek.zshipu.com/tags/web/">web</a>
    
    <a href="https://geek.zshipu.com/tags/web3/">web3</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%B8%80%E8%87%B4%E6%80%A7/">一致性</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%B8%91%E5%B0%8F%E9%B8%AD%E5%AE%9A%E7%90%86/">丑小鸭定理</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%B8%9A%E5%8A%A1/">业务</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%B8%9A%E5%8A%A1%E7%BA%BF/">业务线</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%B8%AA%E6%80%A7%E5%8C%96%E6%8E%A8%E8%8D%90/">个性化推荐</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%B8%AA%E6%80%A7%E5%8C%96%E6%B5%B7%E6%8A%A5/">个性化海报</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%B8%AD%E5%85%B3%E6%9D%91/">中关村</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D/">中文分词</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%B8%AD%E6%96%87%E7%BA%A0%E9%94%99/">中文纠错</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%B8%BB%E9%A2%98%E5%BB%BA%E6%A8%A1/">主题建模</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%B9%A6%E7%B1%8D/">书籍</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%BA%8B%E4%BB%B6%E9%A9%B1%E5%8A%A8%E6%9E%B6%E6%9E%84/">事件驱动架构</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%BA%8B%E5%8A%A1/">事务</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%BA%9A%E9%A9%AC%E9%80%8A/">亚马逊</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/">交叉验证</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">人工智能</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%BA%BA%E6%9C%BA%E9%97%AE%E7%AD%94/">人机问答</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%BE%9B%E5%BA%94%E9%93%BE/">供应链</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%BE%9D%E5%AD%98%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90/">依存句法分析</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/">信息检索</a>
    
    <a href="https://geek.zshipu.com/tags/%E4%BF%A1%E6%81%AF%E6%B5%81%E6%8E%A8%E8%8D%90/">信息流推荐</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/">倒排索引</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%80%92%E6%8E%92%E8%A1%A8/">倒排表</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/">假设检验</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%85%A8%E6%96%87%E7%B4%A2%E5%BC%95/">全文索引</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%85%A8%E6%B0%91K%E6%AD%8C/">全民K歌</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%85%A8%E9%93%BE%E8%B7%AF%E5%8E%8B%E6%B5%8B/">全链路压测</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%85%AC%E5%B9%B3%E9%94%81/">公平锁</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%85%B3%E7%B3%BB/">关系</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%85%B4%E8%B6%A3/">兴趣</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%86%85%E5%AE%B9%E6%8C%96%E6%8E%98/">内容挖掘</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%86%85%E5%AE%B9%E7%90%86%E8%A7%A3/">内容理解</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%86%B3%E7%AD%96%E6%A0%91/">决策树</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%86%B7%E5%90%AF%E5%8A%A8/">冷启动</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%87%BA%E8%BD%A8/">出轨</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%88%86%E5%B1%82%E5%AE%9E%E9%AA%8C/">分层实验</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/">分布式</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/">分布式事务</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/">分布式系统</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/">分布式锁</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%88%86%E8%AF%8D/">分词</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%88%9B%E4%B8%9A/">创业</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8A%A0%E6%9D%83%E8%9E%8D%E5%90%88/">加权融合</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8C%97%E4%BA%AC/">北京</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8C%BA%E5%9D%97/">区块</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8C%BA%E5%9D%97%E9%93%BE/">区块链</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8D%8F%E5%90%8C%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C/">协同记忆网络</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4/">协同过滤</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8D%8F%E6%96%B9%E5%B7%AE/">协方差</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/">单元测试</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8D%9A%E5%A3%AB/">博士</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8D%9A%E5%A3%ABoffer/">博士offer</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8E%8B%E6%B5%8B/">压测</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8E%9F%E5%88%99/">原则</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8F%8C%E5%A1%94%E6%A8%A1%E5%9E%8B/">双塔模型</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8F%8D%E4%BD%9C%E5%BC%8A/">反作弊</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8F%8D%E6%AC%BA%E8%AF%88/">反欺诈</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8F%8D%E8%84%86%E5%BC%B1/">反脆弱</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8F%98%E9%87%8F/">变量</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8F%AC%E5%9B%9E/">召回</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8F%AC%E5%9B%9E%E7%8E%87/">召回率</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8F%AF%E8%A7%82%E6%B5%8B%E6%80%A7/">可观测性</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/">可解释性</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%90%88%E7%BA%A6/">合约</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%90%8E%E5%8E%82%E6%9D%91/">后厂村</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%90%91%E9%87%8F%E5%8F%AC%E5%9B%9E/">向量召回</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2/">向量检索</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%90%91%E9%87%8F%E7%B4%A2%E5%BC%95/">向量索引</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%90%B4%E6%81%A9%E8%BE%BE/">吴恩达</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/">命名实体识别</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%93%8D%E5%BA%94%E5%BC%8F%E7%BC%96%E7%A8%8B/">响应式编程</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%95%86%E6%B1%A4%E7%A7%91%E6%8A%80/">商汤科技</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/">回归模型</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%9B%A0%E6%9E%9C%E5%88%86%E6%9E%90/">因果分析</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/">图像检索</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/">图像识别</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/">图数据库</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%9B%BE%E7%81%B5%E5%B9%B3%E5%8F%B0/">图灵平台</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%9B%BE%E7%89%87%E7%BF%BB%E8%AF%91/">图片翻译</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%9B%BE%E8%AE%A1%E7%AE%97/">图计算</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0/">在线学习</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%9D%90%E6%A0%87%E5%9B%9E%E5%BD%92/">坐标回归</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%A2%9E%E9%87%8F%E5%AD%A6%E4%B9%A0/">增量学习</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%A4%9A%E5%A4%9A/">多多</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%A4%9A%E6%A8%A1%E6%80%81/">多模态</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%A4%9A%E7%9B%AE%E6%A0%87%E4%BC%98%E5%8C%96/">多目标优化</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91/">大数据开发</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%A4%B4%E6%9D%A1/">头条</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%A5%A5%E5%8D%A1%E5%A7%86%E5%89%83%E5%88%80/">奥卡姆剃刀</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%AD%A6%E4%B9%A0/">学习</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/">学习资料</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90/">学习资源</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%AD%A6%E4%BC%9A%E6%8F%90%E9%97%AE/">学会提问</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/">实体识别</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%AE%9E%E6%97%B6%E6%8E%A8%E8%8D%90/">实时推荐</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%AE%9E%E6%97%B6%E6%95%B0%E4%BB%93/">实时数仓</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%AE%9E%E6%97%B6%E6%95%B0%E6%8D%AE/">实时数据</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%AE%9E%E6%97%B6%E6%97%A5%E5%BF%97%E6%94%B6%E9%9B%86/">实时日志收集</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%AE%9E%E6%97%B6%E8%AE%A1%E7%AE%97/">实时计算</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%AE%9E%E9%AA%8C%E5%B9%B3%E5%8F%B0/">实验平台</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%AE%B9%E7%81%BE%E4%BD%93%E7%B3%BB%E5%BB%BA%E8%AE%BE/">容灾体系建设</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">对比学习</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F/">对话系统</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%B0%8F%E5%9F%8E%E5%B8%82/">小城市</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%B0%8F%E7%B1%B3/">小米</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%B0%8F%E7%B1%B3%E6%90%9C%E7%B4%A2/">小米搜索</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%B0%8F%E7%BE%A4%E6%95%88%E5%BA%94/">小群效应</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%B7%A5%E4%BD%9C/">工作</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/">布隆过滤器</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%B8%AE%E5%B8%AE/">帮帮</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%B9%B4%E8%BD%BB%E4%BA%BA/">年轻人</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%B9%BF%E5%91%8A/">广告</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%B9%BF%E5%91%8A%E7%B3%BB%E7%BB%9F/">广告系统</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%BA%8F%E5%88%97%E6%A0%87%E6%B3%A8/">序列标注</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%BB%BA%E6%A8%A1%E8%B0%83%E5%8F%82/">建模调参</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E9%9B%86/">开源数据集</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/">开源项目</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/">异常检测</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%BC%82%E6%AD%A5IO/">异步IO</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%BC%A0%E5%98%89%E4%BD%B3/">张嘉佳</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/">强化学习</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%BD%92%E4%B8%80%E5%8C%96/">归一化</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%BE%85%E5%88%86%E7%B1%BB/">待分类</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/">微服务</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%BE%AE%E8%BD%AFEXP/">微软EXP</a>
    
    <a href="https://geek.zshipu.com/tags/%E5%BE%AE%E8%BD%AF%E4%BA%9A%E6%B4%B2%E7%A0%94%E7%A9%B6%E9%99%A2/">微软亚洲研究院</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%80%9D%E7%BB%B4/">思维</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/">性能优化</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/">情感分析</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%84%8F%E5%9B%BE%E8%AF%86%E5%88%AB/">意图识别</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%88%BF%E7%A7%9F/">房租</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%8A%80%E6%9C%AF/">技术</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%8B%86%E5%88%86/">拆分</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%8B%9B%E8%81%98/">招聘</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%8B%BC%E5%A4%9A%E5%A4%9A/">拼多多</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98/">持续交付</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90/">持续集成</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/">损失函数</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%8E%92%E5%BA%8F/">排序</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%8E%92%E5%BA%8F%E6%A8%A1%E5%9E%8B/">排序模型</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%8E%92%E9%98%9F/">排队</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%8E%A8%E7%90%86%E7%B3%BB%E7%BB%9F/">推理系统</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%8E%A8%E8%8D%90/">推荐</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%8E%A8%E8%8D%90%E7%90%86%E7%94%B1/">推荐理由</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">推荐系统</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%8E%A8%E9%80%81%E5%B9%B3%E5%8F%B0/">推送平台</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%8F%90%E9%97%AE%E7%9A%84%E6%99%BA%E6%85%A7/">提问的智慧</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%90%9C%E7%B4%A2/">搜索</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%90%9C%E7%B4%A2%E5%B9%BF%E5%91%8A/">搜索广告</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E/">搜索引擎</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%90%9C%E7%B4%A2%E6%8E%92%E5%BA%8F/">搜索排序</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%90%9C%E7%B4%A2%E6%9E%B6%E6%9E%84/">搜索架构</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%90%9C%E7%B4%A2%E7%B3%BB%E7%BB%9F/">搜索系统</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F/">支持向量</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/">支持向量机</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%95%B0%E4%BB%93%E4%BD%93%E7%B3%BB/">数仓体系</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%95%B0%E4%BB%93%E5%B9%B3%E5%8F%B0/">数仓平台</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%95%B0%E6%8D%AE%E4%B8%AD%E5%8F%B0/">数据中台</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/">数据仓库</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/">数据分析</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%B9%B3%E5%8F%B0/">数据分析平台</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/">数据同步</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0/">数据平台</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%87%E6%A0%87/">数据指标</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86/">数据治理</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%95%B0%E6%8D%AE%E6%B9%96/">数据湖</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/">数据科学</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%95%B0%E6%8D%AE%E9%9B%86/">数据集</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8/">数据驱动</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%96%87%E5%AD%97%E8%AF%86%E5%88%AB/">文字识别</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%96%87%E6%91%98/">文摘</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/">文本分类</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%96%87%E6%9C%AC%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB/">文本情感分类</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%96%87%E6%9C%AC%E6%8C%96%E6%8E%98/">文本挖掘</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%96%87%E6%9C%AC%E7%BA%A0%E9%94%99/">文本纠错</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%96%87%E6%9C%AC%E8%A1%A8%E5%BE%81/">文本表征</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%96%B0%E9%97%BB%E6%8E%A8%E8%8D%90/">新闻推荐</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%96%B9%E6%B3%95%E8%AE%BA/">方法论</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%97%A5%E5%BF%97%E6%9E%B6%E6%9E%84/">日志架构</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%97%A5%E5%BF%97%E6%A3%80%E7%B4%A2/">日志检索</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%97%B6%E5%BA%8F%E7%89%B9%E5%BE%81%E6%8C%96%E6%8E%98/">时序特征挖掘</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%99%BA%E6%85%A7%E7%89%A9%E6%B5%81/">智慧物流</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/">智能合约</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D/">智能客服</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%99%BA%E8%83%BD%E7%89%A9%E6%B5%81/">智能物流</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%99%BA%E8%83%BD%E8%AF%AD%E9%9F%B3/">智能语音</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%99%BA%E8%83%BD%E9%97%AE%E7%AD%94/">智能问答</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%99%BA%E8%83%BD%E9%A2%84%E8%AD%A6/">智能预警</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%9C%8D%E5%8A%A1/">服务</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%88%B1%E5%A5%BD%E8%80%85/">机器学习爱好者</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%9D%A2%E8%AF%95%E9%A2%98/">机器学习面试题</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/">机器翻译</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89/">机器视觉</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%9C%BA%E5%99%A8%E9%98%85%E8%AF%BB/">机器阅读</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%9D%A1%E4%BB%B6%E9%9A%8F%E6%9C%BA%E5%9C%BA/">条件随机场</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%9E%B6%E6%9E%84/">架构</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%9E%B6%E6%9E%84%E5%B8%88/">架构师</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%A0%87%E7%AD%BE/">标签</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%A0%87%E7%AD%BE%E5%B9%B3%E6%BB%91/">标签平滑</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%A0%87%E7%AD%BE%E8%AF%86%E5%88%AB/">标签识别</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%A0%87%E7%AD%BE%E9%80%89%E6%8B%A9/">标签选择</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%A0%A1%E6%8B%9B/">校招</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%A0%B7%E6%9C%AC/">样本</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%A3%80%E7%B4%A2%E5%BC%95%E6%93%8E/">检索引擎</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%A7%BD%E4%BD%8D%E8%AF%86%E5%88%AB/">槽位识别</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%A8%A1%E5%9E%8B%E5%89%AA%E6%9E%9D/">模型剪枝</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9/">模型压缩</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88/">模型融合</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/">模型评估</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2/">模型部署</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%A8%A1%E5%9E%8B%E9%A2%84%E4%BC%B0/">模型预估</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%A8%A1%E5%BC%8F%E5%8C%B9%E9%85%8D/">模式匹配</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB/">模式识别</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%AD%A3%E5%88%99%E5%8C%96/">正则化</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/">注意力机制</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%B4%8B%E7%A0%81%E5%A4%B4/">洋码头</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%B5%81%E6%89%B9%E4%B8%80%E4%BD%93/">流批一体</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/">消息队列</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%B7%B1%E5%BA%A6/">深度</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%B7%B1%E5%BA%A6%E5%85%B4%E8%B6%A3%E7%BD%91%E7%BB%9C/">深度兴趣网络</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%B7%B1%E5%BA%A6%E6%A0%91%E5%8C%B9%E9%85%8D/">深度树匹配</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%B7%B1%E5%BA%A6%E6%A0%91%E6%A3%80%E7%B4%A2/">深度树检索</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%B7%B7%E6%8E%92/">混排</a>
    
    <a href="https://geek.zshipu.com/tags/%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B/">混沌工程</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%81%AB%E7%84%B0%E5%9B%BE/">火焰图</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%83%AD%E7%82%B9%E6%8C%96%E6%8E%98/">热点挖掘</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%86%94%E6%96%AD%E9%99%8D%E7%BA%A7/">熔断降级</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%88%AC%E8%99%AB/">爬虫</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%88%B1%E5%A5%87%E8%89%BA/">爱奇艺</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%89%9B%E9%A1%BF-%E8%8E%B1%E5%B8%83%E5%B0%BC%E8%8C%A8/">牛顿-莱布尼茨</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%89%A9%E6%B5%81/">物流</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/">特征工程</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%89%B9%E5%BE%81%E5%B9%B3%E5%8F%B0/">特征平台</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%89%B9%E5%BE%81%E7%B3%BB%E7%BB%9F/">特征系统</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%8C%9C%E4%BD%A0%E5%96%9C%E6%AC%A2/">猜你喜欢</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%94%A8%E6%88%B7%E5%BB%BA%E6%A8%A1/">用户建模</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%94%A8%E6%88%B7%E7%94%BB%E5%83%8F/">用户画像</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%94%B5%E5%95%86%E6%90%9C%E7%B4%A2/">电商搜索</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%99%BD%E5%85%94/">白兔</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%99%BE%E5%BA%A6/">百度</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0/">相关系数</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%9C%9F%E8%AF%9D/">真话</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%9F%A2%E9%87%8F%E8%AF%AD%E4%B9%89/">矢量语义</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%9F%A5%E4%B9%8E%E6%9E%B6%E6%9E%84/">知乎架构</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/">知识图谱</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%9F%A5%E8%AF%86%E5%A2%9E%E5%BC%BA/">知识增强</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F/">知识蒸馏</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%9F%AD%E6%96%87%E6%9C%AC%E8%A7%A3%E6%9E%90/">短文本解析</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%9F%AD%E8%A7%86%E9%A2%91/">短视频</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%9F%AD%E8%AF%AD%E6%8A%BD%E5%8F%96/">短语抽取</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%9F%AD%E8%AF%AD%E6%8C%96%E6%8E%98/">短语挖掘</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%A2%A7%E6%A1%82%E5%9B%AD/">碧桂园</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%A5%9E%E9%A9%AC%E6%90%9C%E7%B4%A2/">神马搜索</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%A6%BB%E7%BA%BF%E8%AE%A1%E7%AE%97/">离线计算</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%A7%92%E6%9D%80%E6%9E%B6%E6%9E%84/">秒杀架构</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F/">秒杀系统</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/">程序人生</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%A8%8B%E5%BA%8F%E5%91%98/">程序员</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%A8%B3%E5%AE%9A%E6%80%A7%E8%A7%84%E8%8C%83/">稳定性规范</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%A9%BA%E9%97%B4%E7%B4%A2%E5%BC%95/">空间索引</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0/">窗口函数</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%AB%AF%E4%B8%8A%E6%99%BA%E8%83%BD/">端上智能</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%AB%AF%E6%99%BA%E8%83%BD/">端智能</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%AE%97%E6%B3%95/">算法</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%B1%BB%E5%8D%8F%E5%90%8C%E8%AE%AD%E7%BB%83/">类协同训练</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%B1%BB%E7%9B%AE%E8%AF%86%E5%88%AB/">类目识别</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%B2%97%E6%8E%92/">粗排</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%B4%A2%E5%BC%95/">索引</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%BA%BF%E7%A8%8B/">线程</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/">线程池</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%BC%93%E5%AD%98/">缓存</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%BD%91%E7%BB%9C%E5%9B%BE/">网络图</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%BD%AE%E4%BF%A1%E5%BA%A6/">置信度</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%BE%8E%E5%9B%A2/">美团</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%BE%8E%E5%9B%A2%E5%A4%A7%E8%84%91/">美团大脑</a>
    
    <a href="https://geek.zshipu.com/tags/%E7%BE%8E%E5%9B%A2%E7%82%B9%E8%AF%84/">美团点评</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%81%8C%E5%9C%BA/">职场</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0/">联邦学习</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%85%BE%E8%AE%AF%E6%8A%80%E6%9C%AF/">腾讯技术</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%85%BE%E8%AE%AF%E9%9F%B3%E4%B9%90/">腾讯音乐</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/">自动化测试</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6/">自动驾驶</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%89%B2%E6%83%85%E8%AF%86%E5%88%AB/">色情识别</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%8A%B1%E6%A4%92%E7%9B%B4%E6%92%AD/">花椒直播</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%8B%9E%E8%B0%B7/">苞谷</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%9A%82%E8%9A%81%E9%87%91%E6%9C%8D/">蚂蚁金服</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%A7%84%E5%88%99%E5%B9%B3%E5%8F%B0/">规则平台</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E/">规则引擎</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%A7%86%E9%A2%91%E6%8E%A8%E8%8D%90/">视频推荐</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AE%A1%E7%AE%97%E5%B9%BF%E5%91%8A/">计算广告</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AE%A4%E7%9F%A5/">认知</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AE%A8%E8%AE%BA%E5%8C%BA/">讨论区</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AE%B0%E5%BF%86%E5%BB%BA%E6%A8%A1/">记忆建模</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C/">记忆网络</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AE%BA%E6%96%87/">论文</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/">评价指标</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AF%84%E6%B5%8B%E6%8C%87%E6%A0%87/">评测指标</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AF%8D%E5%90%91%E9%87%8F/">词向量</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AF%8D%E5%B5%8C%E5%85%A5/">词嵌入</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AF%8D%E6%9D%83%E9%87%8D/">词权重</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/">语义分割</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AF%AD%E4%B9%89%E5%8C%B9%E9%85%8D/">语义匹配</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AF%AD%E4%B9%89%E6%A3%80%E7%B4%A2/">语义检索</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AF%AD%E4%B9%89%E6%A8%A1%E5%9E%8B/">语义模型</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AF%AD%E4%B9%89%E7%90%86%E8%A7%A3/">语义理解</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">语言模型</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AF%AD%E9%9F%B3%E5%86%85%E5%AE%B9%E8%AF%86%E5%88%AB/">语音内容识别</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/">语音识别</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%B0%B7%E6%AD%8C%E9%9D%A2%E8%AF%95/">谷歌面试</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%B8%AA%E6%80%A7%E5%8C%96%E6%8E%92%E5%BA%8F/">贝叶斯个性化排序</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%B4%9D%E5%A3%B3%E6%89%BE%E6%88%BF/">贝壳找房</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%B4%9D%E5%A3%B3%E6%99%BA%E6%90%9C/">贝壳智搜</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%B4%A7%E5%B8%81%E5%8C%96/">货币化</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%B5%B7%E6%AD%A5/">起步</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%B6%8B%E5%8A%BF%E7%A7%91%E6%8A%80/">趋势科技</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%B7%AF%E5%BE%84%E8%A7%84%E5%88%92/">路径规划</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%BD%AF%E5%AE%9E%E5%8A%9B/">软实力</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%BE%B9%E7%BC%98%E8%AE%A1%E7%AE%97/">边缘计算</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%BE%BE%E6%91%A9%E9%99%A2/">达摩院</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0/">迁移学习</a>
    
    <a href="https://geek.zshipu.com/tags/%E8%BF%87%E6%8B%9F%E5%90%88/">过拟合</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/">逻辑回归</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%80%BB%E8%BE%91%E6%80%9D%E7%BB%B4/">逻辑思维</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%87%87%E8%B4%AD/">采购</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%87%8D%E5%8F%A0%E5%AE%9E%E9%AA%8C%E6%A1%86%E6%9E%B6/">重叠实验框架</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%87%8D%E6%8E%92%E5%BA%8F/">重排序</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%87%8D%E6%9E%84/">重构</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%87%91%E8%9E%8D/">金融</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%93%B6%E6%B1%A4%E5%8C%99/">银汤匙</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%93%BE%E8%A1%A8/">链表</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%93%BE%E8%A1%A8%E6%B1%82%E4%BA%A4%E9%9B%86/">链表求交集</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%98%BF%E9%87%8C/">阿里</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%98%BF%E9%87%8C%E4%BA%91/">阿里云</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%98%BF%E9%87%8C%E5%A6%88%E5%A6%88/">阿里妈妈</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%98%BF%E9%87%8C%E5%B0%8F%E8%9C%9C/">阿里小蜜</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%98%BF%E9%87%8C%E8%BE%BE%E6%91%A9%E9%99%A2/">阿里达摩院</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%99%88%E8%96%87/">陈薇</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%99%8C%E9%99%8C/">陌陌</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%99%8D%E7%BA%AC%E6%89%93%E5%87%BB/">降纬打击</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%9A%8F%E6%9C%BA%E5%8F%98%E9%87%8F/">随机变量</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%9B%B6%E6%8B%B7%E8%B4%9D/">零拷贝</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%9D%A2%E7%BB%8F/">面经</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%9D%A2%E8%AF%95/">面试</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/">项目管理</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%A2%84%E4%BC%B0%E5%BC%95%E6%93%8E/">预估引擎</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%A2%84%E8%AE%AD%E7%BB%83/">预训练</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%A2%86%E5%9F%9F%E8%AE%BE%E8%AE%A1/">领域设计</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%A2%86%E5%9F%9F%E9%A9%B1%E5%8A%A8/">领域驱动</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%A3%8E%E6%8E%A7/">风控</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%A3%8E%E6%8E%A7%E7%B3%BB%E7%BB%9F/">风控系统</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/">高可用</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%AB%98%E5%B9%B6%E5%8F%91/">高并发</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%AB%98%E6%96%AF%E7%83%AD%E5%9B%BE/">高斯热图</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%AB%98%E7%BB%B4%E6%95%B0%E6%8D%AE%E7%B4%A2%E5%BC%95/">高维数据索引</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%BB%84%E5%B3%A5/">黄峥</a>
    
    <a href="https://geek.zshipu.com/tags/%E9%BB%91%E7%9B%92%E6%A8%A1%E5%9E%8B/">黑盒模型</a>
    
</div>
    </section>

    
<section class="widget">
    <h3 class="widget-title">友情链接</h3>
    <ul class="widget-list">
        
        <li>
            <a target="_blank" href="https://blog.zshipu.com//" title="知识铺的博客">知识铺的博客</a>
        </li>
        
    </ul>
</section>


    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://geek.zshipu.com/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>